\begin{frontmatter}


\title{\ourtitle\protect\thanksref{T1}}
\runtitle{MLE for Score-Driven Models}
\thankstext{T1}{%
        We thank Peter Boswijk, Christian Francq,  Andrew Harvey, and Anders Rahbek, 
        as well as the participants of the 
        ``Workshop on Dynamic Models driven by the Score of Predictive Likelihoods'', Amsterdam; 
        the  ``7th International    Conference on Computational and Financial Econometrics'', London; 
        the ``Workshop on Dynamic Models driven by the Score of Predictive Likelihoods'', Tenerife; 
        the IAAE London conference;
        and seminar participants at Vrije Universiteit Amsterdam, University of Cologne, CREST Paris, 
        and University of Maastricht,
        for helpful comments and discussions.
%       Blasques and Lucas thank the Dutch National Science Foundation (NWO; grant VICI453-09-005) for financial support.
%       Koopman acknowledges support from CREATES, Aarhus University, Denmark, funded by the Danish National Research Foundation, (DNRF78).
}

\begin{aug}
\author{\fnms{Francisco} \snm{Blasques}\thanksref{a,t1}\ead[label=e1]{f.blasques@vu.nl}}
\author{\fnms{Siem Jan} \snm{Koopman}\thanksref{a,b,t2}\ead[label=e2]{s.j.koopman@vu.nl}}\\
\author{\fnms{Andr\'e} \snm{Lucas}\thanksref{a,t1}\ead[label=e3]{a.lucas@vu.nl}}
\runauthor{F.\ Blasques, S.J.\ Koopman, A.\ Lucas}

\thankstext{t1}{Supported by the Dutch National Science Foundation (NWO, grant VICI453-09-005.}
\thankstext{t2}{Funded by the Danish National Research Foundation (DNRF78).}
%\affiliation{VU University Amsterdam and Tinbergen Institute\thanksmark{m1}\\CREATES, Aarhus University$^{\ddagger}$}

\address[a]{Vrije Universiteit Amsterdam and Tinbergen Institute,
De Boelelaan 1105,
NL-1081HV Amsterdam.
%The Netherlands.%\\
Email: \printead{e1,e2,e3}.
%\phantom{E-mail:\ }\printead*{e2}\\
%\phantom{E-mail:\ }\printead*{e3}
}
\address[b]{CREATES, Aarhus University}

\end{aug}



\begin{abstract}
\noindent  We establish the strong consistency and asymptotic normality of the maximum likelihood estimator for time-varying parameter models driven by the score of the predictive likelihood function. 
We formulate primitive %(rather than high-level) 
conditions for global identification, invertibility, strong consistency, and asymptotic normality under both correct specification and mis-specification of the model. 
%We subsequently use these results to establish the information theoretic optimality of score-driven models when the true conditional density of the data varies smoothly over time. 
%We illustrate our results using a score-driven time-varying parameter model under skewness and fat tails. 
A detailed illustration is provided for a conditional volatility model with disturbances from the Student's t distribution.
\end{abstract}

\begin{keyword}
\kwd{score-driven models}
\kwd{time-varying parameters}
%\kwd{Kullback-Leibler local optimality}
\kwd{Markov processes}
\kwd{stationarity}
\kwd{invertibility}
\kwd{consistency}
\kwd{asymptotic normality}
\end{keyword}


\end{frontmatter}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\section{Introduction} 
% (fold) 


%what do we do: KABAM
\noindent  We consider the class of score-driven models introduced in \citet{CKL2011,CKL2013} and \citet{harvey2013}. 
Score-driven models encompass many well-known time-varying parameter models from the literature, such as the generalized autoregressive conditional heteroskedasticity (GARCH) model of \citet{Engle82A} and \citet{Bollerslev86}, the autoregressive conditional duration (ACD) model of \citet{EngleRussell1998}, the multiplicative error model (MEM) of \cite{Engle2002}, and many more. 
%Moreover
Also, score-driven models have recently given rise to 
%a whole 
new literature on empirically successful models, including 
new dynamic models for location and scale of fat-tailed data \citep{harveyluati2014}, 
%new 
models for mixed measurement dynamic factor structures \citep{cskl2014},
%new 
models for dynamic spatial processes \citep{blasques2016,catania2017},
and 
%new 
models for dynamic copulas, 
both with short-memory dynamics \citep{CKL2011, lucasschwaabzhang2014, lucasschwaabzhang2017},
long-memory dynamics \citep{jkl2014}, 
factor structures \citep{ohpatton2017b},
and with realized measures as inputs \citep{delirasalvatierrapatton2015,opschoor2017}.%
\footnote{%
	For a more complete overview of contributions in score-driven models, see \href{http://gasmodel.com}{http://gasmodel.com}.
} %
Despite the impressive wide range of new models with score-driven dynamics, 
%hardly any theoretical results are available 
there are not many theoretical results presented
for the estimators of the underlying static parameters in such models. The main complication lies in the non-linearity of the stochastic recurrence equations defining score-driven models. Therefore, in this paper we make a first important step to fill this gap by deriving new asymptotic results for parameter estimation in the class of score-driven models. In contrast to most of the literature, we have chosen to derive such results in the global rather than in the simpler local setting, while building on low-level rather than high-level conditions.

%that are known respectively as generalized autoregressive score-driven models or dynamic conditional score-driven models. 
%We let the general class of score-driven nonlinear time series models be defined by
In general, a score-driven model is specified by the equations
% as follows,
\bq{intro2}
\begin{split}
    \dDatat &\sim \fDensY(\dDatat | \dFt; \dlambda), \\
    \dFtp &= \domega + \dalpha\, 
%    \fScaledScore(\dFt, \dDatat; \dlambda) 
    \fScaledScore_{\iTime}
    + \dbeta \dFt, \vspace{0.3cm}\\ 
    \fScaledScoret &  = 
    %\fScaledScore(\dFt, \dDatat; \dlambda) = 
    \fScale(\dFt; \dlambda) \cdot \fScore(\dFt,\dDatat;\dlambda),\\
 \fScore(\dFt,\dDatat;\dlambda) & = \partial \NatLog \fDensY(\dDatat| \dFt; \dlambda)/\partial \dFt ,
\end{split}
\eq
where $\dDatat$ denotes the observed data,
$\dFt$ is a time-varying parameter characterizing the conditional density $\fDensY$ of $\dDatat$, $\fScoret := \fScore(\dFt,\dDatat;\dlambda)$ 
denotes score of the predictive conditional density, and $\fScaledScoret$ denotes the scaled score 
%i.e., 
%$\fScaledScore(\dFt, \dDatat; \dlambda)$ 
for some choice of scaling function $\fScale(\dFt; \dlambda)$.
The static parameters in the density $\fDensY$ are collected in a vector $\dlambda$
while all static parameters, including the updating coefficients
$\domega$, $\dalpha$, and $\dbeta$, are gathered in the
parameter vector
$\dtheta=(\domega,\dalpha,\dbeta, \dlambda\trans)\trans$ with $\trans$ denoting transposition.

A distinguishing feature of the model in \eqref{intro2} is the use of the scaled score $\fScaledScoret$ in the transition equation for $\dFt$.
A popular example of a score-driven model is the Student's $t$ conditional volatility model, given by 
\bq{intro2b}
\begin{split}
    \dDatat &= \dFt^{1/2}\cdot \ept, \\
    \dFtp &= \domega + \dalpha\, \left(
    \dwt \,\dDatat^2 - \dFt
    \right)
    + \dbeta \dFt,\\
\dwt &= 
(1+\dlambda^{-1})/(1+\dlambda^{-1}\,\dDatat^2/\dFt),
%\tfrac{(1+\dlambda^{-1})}{1 + \dlambda^{-1}\,\dDatat^2/\dFt},
\end{split}
\eq
where $\{\ept\}_{t \in \mathbb{Z}}$ is a sequence of independent identically distributed random variables with Student's $t$ distribution and $\dlambda$ degrees of freedom; compare  \citet{CKL2011,CKL2013} and \citet{harvey2013}.
The time-varying parameter $\dFt$ represents the conditional volatility in the time series $\dDatat$.
We use this model as our leading example throughout the entire 
%text.
exposition. The model is markedly different from a GARCH model with Student's $t$ innovations. In particular, next period's volatility is not merely driven by the square $\dDatat^2$ of past observations, but rather by the weighted squares using weights $(1+\dlambda^{-1})/(1+\dlambda^{-1}\,\dDatat^2/\dFt)$. These weights tend to zero for large values of $\dDatat^2$. The score-driven dynamics thus automatically correct for outliers if $\dDatat$ is allowed to be conditionally fat-tailed. This is a desirable feature for many financial time series. 
%If $\dDatat$ is allowed to be conditionally fat-tailed, only part of a high value of $\dDatat^2$ is attributed to a volatility increase. The remainder is attributed to the fat-tailedness via the use of the weights. 
In the limit as $\dlambda\to\infty$, the weight $\dwt$ collapses to unity, such that we recover the GARCH model. More details on our leading example and other examples are presented in Section~\ref{sec2.1}.


The score-driven model in equation \eqref{intro2} is observation-driven in the classification of \cite{Cox81}. 
Therefore,
%it easily lends themselves to
maximum likelihood estimation of the static parameter vector 
%of interest $\dtheta_{0}$ 
can easily be achieved via a prediction error decomposition.
In particular, the likelihood function is known in closed-form, which significantly reduces the computational burden.
%This feature is exploited in \citet{klsch2015} to
\citet{blasqueskoopmanlucas2015opt} show that score-driven models have unique optimality properties in terms of approximating the unknown sequence of conditional densities $\fDensY(\dDatat | \dFt; \dlambda)$, even when the model is misspecified. 
Relatedly, using the model confidence set approach of \citet{hansenlundenason2011}, \citet{klsch2015} show that score-driven time-varying parameter models produce similar forecasting precision as parameter-driven state-space models, even if the latter constitute the true data generating process.

We establish an asymptotic statistical theory for the maximum likelihood estimator of the static parameters of score-driven models as specified in (\ref{intro2}). 
%Second, we use use the developed theory to prove a new unconditional optimality result for score-driven models. 
%In particular, for a given observation density we show that these models improve the expected Kullback-Leibler distance between the model and the true data generating process more than any other observation-driven filter.
Our results have a number of distinctive features compared to earlier theoretical contributions on observation-driven and, more specifically, on score-driven models.



%Furthermore, we follow  \cite{smikosch2006} (hereafter referred to as \SMM) and the ergodic theorem in \cite{rao1962} for strictly stationary and ergodic sequences on separable Banach spaces. 
%As in \SMM, we use this approach to obtain 
%our results %strong consistency and asymptotic normality of the MLE 
%under mild differentiability requirements and moment conditions.
%Our asymptotic results continue to hold in case the model is mis-specified
%These conditions are less strict than those typically imposed to obtain uniform convergence through pointwise convergence and stochastic equicontinuity.
%Although our updating equation for the time-varying parameter is more specific than the one used in \SMM, we present results under more general conditions.
%For example, the uniform lower bound on the autoregressive updating function adopted
%in \SMM\ is only appropriate for the MEM class and is too restrictive in our setting.
%We note that the current approach can also be used directly to establish asymptotic normality of the MLE under additional regularity conditions. We have opted to defer results on asymptotic normality to another paper in order not to overburden the current exposition.

First,  our asymptotic properties derived for the maximum likelihood estimator (MLE) are  global in nature.  For example, we provide a global identification result for score-driven models in terms of low-level conditions. 
In particular, we ensure that the likelihood function has a unique global maximum over the entire parameter space. 
Our global result differs from the existing literature that relies on high-level assumptions and only ensures local identification by imposing invertibility conditions on the information matrix at the true parameter value;
see, for example, \cite{smikosch2006} and \cite{harvey2013}.
%
Second, our effort to obtain  primitive \textit{low-level} conditions that are formulated in terms of the basic structure of the model extends well beyond the global identification conditions mentioned above.
%Most other approaches use high-level conditions instead.
For instance, we obtain the required moments of the likelihood function directly from assumptions concerning the properties of the basic building blocks of equation \eqref{intro2}, such as the shape of the density function $\fDensY$.
The use of primitive conditions is typically useful for empirical researchers who want to establish the asymptotic properties of the MLE in their own specific setting of interest. We are able to  obtain low-level conditions by adapting Theorem 3.1 in \cite{bougerol1993}. The adapted theorem not only delivers the strict stationarity and ergodicity of stochastic sequences, but also produces bounded moments of any desired order for the filter.
%
Third, we follow  \cite{smikosch2006} in making use of Theorem 3.1 in \cite{bougerol1993} and the ergodic theorem in \cite{rao1962} for strictly stationary and ergodic sequences on separable Banach spaces. This allows us to establish the invertibility of the score filter and obtain our asymptotic results under weaker differentiability conditions than the existing literature on MLE for score-driven models. 
%
Finally, we explore consistency and asymptotic normality results for both well-specified and mis-specified models.
In this way, our results extend the existing literature for score-driven models, which focus only on the correctly specified case. Furthermore, by allowing for model mis-specification we `align' the asymptotic estimation theory for score-driven models with the existing information-theoretic optimality results established in \citet{blasqueskoopmanlucas2015opt}. 

The newly developed theory presented in this paper allows us to establish results for  a much wider range of score-driven models than those currently studied,
% in the score literature, 
which typically focus on fat-tailed models with log likelihoods that have uniformly bounded third order derivatives; see e.g.~\cite{harvey2013},  \cite{harveyluati2014}, \cite{CaivanoHarvey2014}, and \cite{ryoko2016}. 
In particular,
we emphasize that by establishing the invertibility of the score-driven filter, our asymptotic results stand in sharp contrast to all the existing results on score-driven models, which do not ensure invertibility; see also \citet{AndresHarvey2012} and \citet{HarveyLange2015,HarveyLange2016}.
The importance of filter invertibility for consistency of the MLE has been underlined in \cite{smikosch2006}, \citet{RePEc:pra:mprapa:46027}, and \cite{BGKW2016},  among others. Without invertibility, all the existing asymptotic results on score-driven models must implicitly assume that the first value of the true time-varying parameter, $\dF_{1}$, is random \emph{and} known exactly, while the remaining sequence  $\{\dFt\}_{t \geq 2}$ is unobserved. This seems unrealistic.



%In particular, we obtain all our results for large parameter spaces whose boundaries can be derived analytically or numerically. % 
%This contrasts with typical local identification results that are based on the invertibility of the information matrix and only hold for arbitrarily small parameter spaces containing the true parameter.
%Most other consistency and asymptotic normality results, by contrast, typically hold for arbitrarily small parameter spaces containing the true parameter. 
%The global nature of our approach is intricately linked with establishing invertibility of the score-driven filtering equation \eqref{intro2}. 
%The importance of establishing invertibility for consistency of the MLE has been underlined in \SMM\ and \citet{RePEc:pra:mprapa:46027}, among others. 


%Finally, we show that the MLE converges to a limit point in the parameter space that renders the score-driven model optimal within the class of observation-driven models. In particular,   we show that the score-driven model provides the best possible approximation to the distribution of the data $y_1,\ldots,y_T$, as long as the conditional density  $\fDensY$ varies smoothly over time. This result holds against any other observation-driven model, even if the score-driven model is severely mis-specified, and regardless of incorrect initialization. By considering the entire time series process, this result substantially extends earlier results by \citet{blasqueskoopmanlucas2015opt}, who analyze only  the relative changes in approximation produced by a single updating step. Our optimality criterion uses the expected relative Kullback-Leibler divergence and therefore as firm foundations in information theoretic optimality theory. 
%The results also provide a further strong theoretical foundation for the use of score-driven models in empirical work.

The lack of theoretical results for the class of score-driven models defined in (\ref{intro2}) stands in sharp contrast to the large number of results available for the MLE in GARCH models. We do not attempt to review that literature here; for good overviews, see for instance \cite{straumann2005} or \cite{francqzakoian2010}.
The main cause for the limited theoretical progress for score-driven models lies in their typical complex nonlinear dynamic structure compared to common GARCH models.
This results in new theoretical challenges and puzzles.
%, some of which are highlighted in this paper.
The analysis of score-driven models also provides a different perspective from the standard literature: the characteristics of the likelihood function (based on the conditional density $\fDensY$) in a score-driven model hinge directly together with the dynamic properties of the time-varying parameter (via the use of the score $\partial \NatLog\fDensY/\partial\dFt$ in the transition equation \eqref{intro2} for $\dFt$). This provides an intimate link between the two that departs from most of the literature, where the properties of the likelihood function and the properties of the time-varying parameter dynamics can be dealt with separately.


% NEXT NOT NEEDED; TOO GENERIC

%Reviews of M estimation theory for parametric nonlinear autoregressive models can be 
%found in Gallant and White (1986), White (1991)  and Potscher and Prucha (1997). 
%Properties and applications of a large number of such models can be found in Granger 
%and Terasvirta (2010).  
%MLE theory for the GARCH volatility model of Engle (1982) can be traced back to 
%Weiss (1986), Lee and Hansen (1994) and Lumsdaine (1996). Good reviews of the 
%stochastic properties and estimation of volatility models can be found in Straumann (2005) 
%and \cite{francqzakoian2011}. 

%Weiss AA (1986) Asymptotic theory for ARCH models: estimation and testing. Econometric Theory 2:107â131

%Lee SW, Hansen BE (1994) Asymptotic theory for the GARCH(1,1) quasi- maximum likelihood estimator. Econometric Theory 10:29â52 

%Lumsdaine RL (1996) Consistency and asymptotic normality of the quasi-maximum likelihood estimator in IGARCH(1,1) and covariance stationary GARCH(1,1) models. Econometrica 64:575â596 

%Straumann D (2005) Estimation in conditionally heteroscedastic time series models. Lecture Notes in Statistics, Springer Berlin Heidelberg

%\sjsays{ -- for the referee that likes novel proofs --
%The theoretical proofs are provided in Appendices. We offer a number of novel proofs in the technical developments. In particular, all our results are for large parameter spaces whose boundaries can be derived analytically or numerically. This contrasts with typical local identification results that are based on the invertibility of the information matrix and only hold for arbitrarily small parameter spaces containing the true parameter. The global nature of our approach is intricately linked with establishing invertibility of the score-driven filtering equation \eqref{intro2}. Other novel proofs are concerned with ...
%} 

The remainder of this paper is organized as follows.
Section~\ref{sec2} introduces the model.
%A set of model illustrations is also presented.
%We provide some insightful examples of the class of score-driven models in Section~\ref{secill}.
In Section~\ref{sec3}, we obtain stationarity, ergodicity, 
invertibility, and existence of moments of filtered score-driven sequences using primitive conditions. 
%We do so for both well-specified and mis-specified model settings. 
%This section can be skipped by the reader interested only on verification of conditions for consistency and asymptotic normality of the MLE. 
Section~\ref{sec4} proves global identification, consistency, and asympotic normality of the MLE.
%Section~\ref{sec6} uses the results from Sections~\ref{sec3} and \ref{sec4} to establish our new optimality result.
%In Section~\ref{sec5}, we analyze examples using the theory developed in Sections \ref{sec3} and \ref{sec4}.
Section~\ref{sec7} concludes. 
The proofs of the main theorems are gathered in the Appendix. 
More technical background material is relegated to the online \SupplementaryAppendix\ (\SupplementaryAppendixAbbrev).


%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\section{The Score-Driven Model} % (fold) 
\label{sec2}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

%\subsection{An Introductory Example} \label{sec2.1}
\subsection{An Introduction} \label{sec2.1}

As an intuitive introductory example of score-driven models, we
consider a score-driven time-varying location model of the form
\begin{align}
    \label{eq2.1}
    \dDatat &= \dFt + \ept,
%    \qquad
    &
    \ept &\sim \fDensEp(\ept; \dlambda),
    \\
    \label{eq2.2}
    \dFtp &= \domega + \dalpha \fScoret + \dbeta\dFt,
%    \qquad  
    &
    \fScoret &=\frac{\partial \NatLog \fDensEp(\dDatat - \dFt; \dlambda)}{\partial\dFt}
\end{align}
where $\dFt$ is the time-varying location parameter, $\NatLog$ denotes the natural logarithm, and $\fDensEp$ is the error density that depends on an unknown, static parameter vector $\dlambda$. 
For simplicity, we have set the scaling function from equation~\eqref{intro2} in this example to $\fScale(\dFt; \dlambda) = 1$.
The dynamics of $\dFtp$ can easily be extended by including higher order lags of $\dFt$ and/or of the score $\fScoret = \partial\NatLog\fDensEp(\dDatat-\dFt;\dlambda)/\partial \dFt$, or by imposing structural time series dynamics or including exogenous variables; see for further details \citet{CKL2013}, \citet{harveyluati2014}, and \citet{ordkoehlersnyder1997}.

%In Section \ref{sec6} we show that, among the class of observation-driven updating equations, the use of the score in (\ref{eq2.2}) for updating $f_{t}$ provides us with the best possible approximation of the true unknown distribution of the data. In particular, we show that the score update is locally optimal in an information-theoretic sense when the true conditional density varies smoothly over time. This result is true even if the postulated model density $\fDensY$ is severely mis-specified.  
%For this reason, Section \ref{sec4} first establishes consistency and asymptotic normality of the MLE for both well-specified and mis-specified score-driven models.


If $\fDensEp$ in equation \eqref{eq2.1} is the normal distribution with mean zero and variance $\dlambda$, the score in equation \eqref{eq2.2} becomes $(\dDatat - \dFt)/\dlambda$,
\[
	\dFtp = \domega + \dalpha\,\dlambda^{-1}(\dDatat - \dFt) + \dbeta\,\dFt.
\] 
The location $\dFtp$ then moves linearly up and down with the previous residual value $\dDatat - \dFt$ in an intuitive way. In fact, model \eqref{eq2.1}--\eqref{eq2.2} can be re-written as a standard linear autoregressive moving average (ARMA) model for $\dDatat$ of order $(1,1)$ with autoregressive coefficient $\dbeta$ and moving average coefficient $(\dalpha \, / \, \dlambda)-\dbeta$.

The score-driven model becomes more interesting if we consider a non-normal distribution, such as a Student's $t$ distribution; see \citet{CKL2013} and \citet{harveyluati2014}. In this case, the score-driven model gives rise to an outlier robust filtering approach. Consider a Student's $t$ distribution with mean zero, squared scale parameter $\dlambda_1$ and degrees of freedom parameter $\dlambda_2$. Equation \eqref{eq2.2} then reduces to
\bq{eq2.3}
    \dFtp = \domega + \dalpha\,
    (\dlambda_2+1) 
    \frac
    {(\dDatat - \dFt)}
%   \left/ \left( 
    {\dlambda_1\dlambda_2 + (\dDatat - \dFt)^2}
%   \right) \right.
    + \dbeta \dFt
    ,
\eq
such that the location parameter $\dFtp$ now reacts nonlinearly to past values of $\dFt$ for fixed data $\dDatat$. 
For example, whereas a large residual $(\dDatat-\dFt)$ pushes the next location parameter $\dFtp$ substantially up if the normal distribution is assumed ($\dlambda_2\to\infty$), under the Student's $t$ assumption the impact of such a large residual is of order $(\dDatat-\dFt)^{-1}$. The impact on $\dFtp$ therefore becomes negligible as $(\dDatat-\dFt)$ diverges. The intuition is that such observations are more likely due to the fat-tailedness property of the Student's $t$ distribution than that they are informative about gradual shifts in the location parameter.

%\textcolor{gray}{The asymptotic results derived in \citet{harveyluati2014} are local in nature and specific for the Student's $t$ location-scale model.
%For example, if we go beyond the context of the Student's $t$ distribution and introduce a skewed distribution for $\fDensEp$, new results need to be derived. Such extensions arise easily in scale models with a measurement equation of a multiplicative form and are illustrated below.}
%\andresays{a daring paragraph; rewrite to make less offensive; also: is it really true? maybe kill whole paragraph?}

To elucidate on how the theory as developed in this paper may be applied to a realistic case, we adopt the leading example of a score-driven time-varying volatility model of \citet{CKL2011,CKL2013}. By providing the details for this example, we keep the exposition focused.
%This helps to keep the exposition focused. 
The application of the theory is, however, not limited to this particular case. 
%In \SupplementaryAppendix\ \ref{FurtherApplications}, we provide a 
A substantial range of additional illustrations of the theory can be provided, including 
robust time-varying location models with skewed distributions; 
conditional volatility models for log volatility; 
extensions of  conditional duration (ACD) models of \cite{EngleRussell1998},  \cite{grammigmaurer2000}, \cite{bauwensgiot2000},  and \citet{klsch2015} that allow for fat-tailed densities;
and time-varying location models with non-linear transformations of the location parameter, thus extending examples studied by \citet{harvey2013} and \citet{harveyluati2014}. 
%Together, the illustrations provide a variety of settings where the results of this paper can be applied successfully. 
% 
%
%We now introduce our leading example. In particular, t
%The main example in the paper provides the asymptotic results for the robust and empirically successful univariate volatility models of \citet{CKL2011,CKL2013}. 

\begin{exmcstart} %\rm
Consider the conditional Student's $t$ model with time varying volatility as given by
\bq{eq2.4}
\begin{split}
    \dDatat &= \dFt^{1/2}\cdot \ept, \\
    \dFtp &= \domega + \dalpha\, \left(
%    \tfrac{(1+\dlambda^{-1})}{1 + \dlambda^{-1}\,\dDatat^2/\dFt}\,\dDatat^2 - \dFt
    \left[(1+\dlambda^{-1}) \, / \, (1 + \dlambda^{-1}\,\dDatat^2/\dFt) \right] \,\dDatat^2 - \dFt
    \right)
    + \dbeta \dFt.\\
\end{split}
\eq
where $\{\ept\}_{t \in \mathbb{Z}}$ is a sequence of independent identically distributed random variables from the Student's $t$ distribution with $\dlambda$ degrees of freedom.
We ensure positivity of the scale $\dFt$ by imposing $\dbeta>\dalpha>0$, $\domega>0$, and $\dFoneFixed>0$, where $\dFoneFixed$ is the initial condition for $\dFt$ at time $\iTime=1$.
The raw score is scaled by a factor proportional to the inverse conditional Fisher information as suggested by \citet{CKL2013}, to account for the local curvature of predictive density at time $\iTime$,
i.e.,  $\fScale(\dFt; \dlambda) = 2\dFt^2$.
For the Gaussian case ($\dlambda\to\infty$) we recover a slightly reparameterized version of the standard GARCH model, $\dFtp = \domega + \dalpha\dDatat^2 + (\dbeta - \dalpha)\dFt$.
\end{exmcstart}

Figure \ref{fig:TGAS} provides a typical illustration of the difference between the GARCH dynamics and the score-driven dynamics in \eqref{eq2.4}. Large spikes in $\dDatat^2$, particularly incidental ones such as those at the end of 1987 and 1989, result in a spike in the GARCH volatility, followed by a slow exponential decline. By contrast, the filtered volatility estimate obtained from the Student's $t$ based score-driven dynamics recognizes that the large negative return in 1989 is incidental and is probably due to the fat-tailedness of the data. Similarly for the turmoil at the end of 1987, both volatilities increase, but again the score-driven filtered estimate is considerably more robust and does not exhibit the subsequent non-intuitive strong exponential decline. 

%%%%%%%%
%%%%%%%%
\begin{figure}[!t]
	\centering
		\includegraphics[width=0.8\textwidth]{TGAS-snapshot-eps-converted-to.pdf}
	\caption{Typical differences between GARCH and Student's $t$ based score-driven volatility dynamics\label{fig:TGAS}}
\end{figure}
%%%%%%%%
%%%%%%%%

The intuition for the behavior of the score filter is simple. Consider a large observation $\dDatat$, relative to the current level of volatility $\dFt$.
%^{1/2}$. 
If we assume that tail observations are unlikely because $\dDatat$ is conditionally Gaussian, a large value of $\dDatat$ must be attributed to a (steep) volatility increase.
If, however, we assume that data are conditionally fat-tailed, part of the magnitude of $\dDatat$ can be attributed to the fat-tails. As a result, the volatility needs to be increased much less dramatically.
This is precisely what the score-driven approach attains in this case.
The GARCH dynamics do not account for this: whatever the degree of conditional fat-tailedness, the next volatility level always responds quadratically to any observation $\dDatat$. 
The score-driven dynamics, by contrast, incorporates the trade-off by down-weighting the impact of a large $\dDatat^2$ automatically; see \citet{CKL2011,CKL2013} for more discussions and examples.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The General Setting} \label{sec2.3}
%As illustrated by our leading example from Section~\ref{sec2.1}, a
We next provide a more formal account of the score-driven model in order to derive our asymptotic results.
A score-driven model is characterized by three specific building blocks. 
These include the distributional assumption, the choice of parameterization, and the type of measurement equation. 
We use the following general framework throughout the remainder of this paper.
Consider a $\dimData$-dimensional stochastic sequence $\{\dDatat\}_{t \in \field{N}}$ given by
\bq{measurement}
    \dDatat = 
    \fLink \big(
        \dFt(\dDataSuptm\supcomma \dtheta, \dFoneFixed)\ , \ \eptlambda
    \big),
    \qquad 
    \eptlambda \sim \fDensEp \big( \eptlambda; \dlambda \big),
\eq
where $\fLink:\fF \times \fEp \to \fData$ is a link function that is strictly increasing in its second argument,
$\dFt(\dDataSuptm\supcomma \dtheta, \dFoneFixed)$ is the time-varying parameter function
%with $\dDataSuptm = (\dData_1,\ldots,\dDatatm)$
with outcomes in the convex set $\fF$, 
$\{ \eptlambda \} _{t \in \field{N}}$ is an exogenous i.i.d.\ sequence of random variables for every
parameter vector 
$\dlambda \in \fLambda \subseteq \field{R}^{\dimlambda}$, and
$\fDensEp$ is a density function.  
The time-varying parameter updating scheme is given by
\bq{eqgasupdate}
    \dFtp(\dDataSupt\supcomma \dtheta, \dFoneFixed) = \domega + \dalpha\,  
    \fScaledScore	 \big(
        \dFt(\dDataSuptm\supcomma \dtheta, \dFoneFixed) , \dDatat \, ; \, \dlambda 
    \big) + 
    \dbeta\, \dFt(\dDataSuptm\supcomma \dtheta, \dFoneFixed) ,
\eq
for $\iTime > 1$, and initialized at
$
%    \dFone(\emptyset, \dtheta, \dFoneFixed) = \dFoneFixed \ ,   
    \dFone(\dtheta, \dFoneFixed) = \dFoneFixed    
$
for a nonrandom $\dFoneFixed \in \fF \subseteq \field{R}$.
%where $\emptyset$ is the empty set,
%$\dlambda \in \fLambda \subseteq \field{R}^{\dimlambda}$ is a parameter vector,
The vector $\dtheta\trans =(\domega,\dalpha,\dbeta, \dlambda\trans) \in \fTheta \subseteq \field{R}^{\dimtheta}$
is the static parameter vector,
%with $\trans$ denoting transposition,
%$\fDensEp$ is a density function,  
and $\fScaledScore: \fF \times \fData \times \fLambda \to \fF$ is the scaled score of the conditional density of $\dDatat$ given $\dFt$.
%and with scaling function $\fScale(\dFt; \dlambda)$.
For ease of exposition, we assume that $\dlambda$ is a scalar, that is $\dimsymbol_{\dlambda}=1$.
Whenever possible, we suppress the dependence of %$\eptlambda$ and
$\dFt(\dDataSuptm\supcomma \dtheta,\dFoneFixed)$ on 
its arguments
and write %$\ept$ and 
$\dFt$ instead. % , respectively. 

\begin{exmc} %\rm
For the time-varying volatilty model of Section \ref{sec2.1}, the link function $\fLink$ in \eqref{measurement} simplifies to $\fLink(\dFt,\ept) = \dFt^{1/2}\cdot\ept$, which is strictly increasing in $\ept$ if $\dFt>0$.
For a location model, the link function is additive.
Depending on the application the link function may also be much more complex, such as for the Beta distribution with time-varying parameters in \citet{cskl2014}.
\end{exmc}

%Also, when there is no risk of confusion, we drop subscripts from the sets $\fFg = \fFs = \fF$ etc., so that the functions $\fLink$ and $\fScaledScore$ are assumed to be defined on the common support $\fF$. We only make a strict separation between these sets when needed, particularly in the proof of our identification result in Theorem~\ref{theo3}.
%We display a symbol in bold when it refers to a vector or to a matrix.

We define $\fDensY (\dDatat  |  \dFtildet  ;  \dlambda  )$ as the conditional density of $\dDatat$ given 
$\dFtildet$,%:=\dFtArgs$, 
\bq{likcomponents}
   \fDensY\big(\dDatat \ \big| \ \dFtArgs \ ; \ \dlambda \big) =
   \fDensEp\big(\fLinktilde(\dFtildet  ,  \dDatat) \ ; \ \dlambda \big) \cdot
   \fLinktilde'(\dFtildet , \dDatat ),
\eq
where 
$$\fLinktildet := \fLinktilde(\dFtildet,\dDatat) : =  \fLinkInverse (\dFtildet,\dDatat),$$ 
is the inverse of $\fLink(\dFtildet, \ept)$ with respect to its second argument, $\ept$,
and where $\fLinktildet': = \fLinktilde'(\dFtildet,\dDatat ) : = 
\partial \fLinktilde (\dFtildet,\dData )/ \partial \dData|_{\dData=\dDatat}$ is the Jacobian of the transformation.


\begin{exmc} %\rm
For the volatility model from Section~\ref{sec2.1}, we have $\fLink(\dFt,\ept) = \dFt^{1/2}\cdot\ept$, and thus $\fLinktildet = \fLinkInverse(\dFtildet,\dDatat) = \dDatat/\dFt^{1/2}$ and $\fLinktildet' = \dFt^{-1/2}$.
\end{exmc}

The defining aspect of the score-driven model is its use of the scaled score function as the
driving mechanism in transition equation \eqref{eqgasupdate}.
The scaled score function is defined as
\bq{eqscoredriver}
%    \fScaledScore \big(\dFtArgs, \dDatat \ ; \  \dlambda \big) = 
    \fScaledScore \big(\dFtildet ,\dDatat\ ; \  \dlambda \big) = 
    \fScale(\dFtildet; \dlambda) \cdot  \fScoret(\dFtildet,\dDatat; \dlambda)
    \left. \quad  \text{where} \quad \fScoret(\dFtildet,\dDatat; \dlambda)= \left[ \frac{\partial \ptildet}{\partial \dF} +  \frac{\partial \fLinktildet'}{\partial \dF} \right]\right|_{\dF=\dFt},
\eq
with $\ptildet := \ptilde(\dFt,\dDatat ;\dlambda) = 
\NatLog \fDensEp(\fLinktilde(\dFt,\dDatat);\dlambda)$
and where $\fScale:\fF \times \fLambda \to \fF$ is a positive scaling function; see \citet{CKL2013}. 


Section~\ref{sec4} establishes the asymptotic properties of the maximum likelihood estimator (MLE) for the static parameter vector $\dtheta$. We define the MLE $\dthetahatT(\dFoneFixed)$  for fixed initial condition $\dFoneFixed$ as
\begin{equation*}
    \dthetahatT(\dFoneFixed) \in \arg\max_{\dtheta \in \fTheta} \LogLikT(\dtheta,\dFoneFixed),
\end{equation*}
with the average log-likelihood function $\LogLikT$ given in closed form as
\begin{equation}
    \label{eqlikfun}
    \begin{split}
        \LogLikT(\dtheta,\dFoneFixed) &  =  
    \frac{1}{\iT}
    \sum_{\iTime=1}^{\iT} \Big( \NatLog \fDensEp(\fLinktildet; \dlambda) + 
    \NatLog \fLinktildet' \Big) = 
    \frac{1}{\iT}\sum_{\iTime=1}^{\iT}  \Big( \ptildet +  \NatLog \fLinktildet' \Big).
    \end{split}
\end{equation}
The availability of a closed-form expression for the likelihood function is one of the computational advantages of observation-driven time-varying parameter models. It has led to the widespread application of GARCH models in applied empirical work.
As is clear from equation \eqref{eqlikfun}, score-driven models benefit from the same computational advantages.

Before the asymptotic properties of MLE can be properly developed, we need to establish in Section \ref{sec3} stationarity, ergodicity, invertibility and moment existence from primitive conditions.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------


\section{Stochastic Properties of Score-Driven Filters} % (fold) 
\label{sec3}

The likelihood function \eqref{eqlikfun} is formulated in terms of the data and in terms of the filtered time-varying parameter $\dFt$ as defined by the recursion \eqref{eqgasupdate}. 
In order for the likelihood function  to be well-behaved and for an appropriate law of large numbers (LLN) and central limit theorem (CLT) to apply, the \emph{filtered} sequence $\{\dFt\}$ as well as the sequences of its first and second order derivatives need to be sufficiently well-behaved for a given data sequence $\{\dDatat\}$. 
Naturally, the filtered $\{\dFt\}$ sequence for given data $\{\dDatat\}$ needs to be carefully distinguished from its model-implied counterpart, which takes the innovations $\{\ept\}$ rather than the data $\{\dDatat\}$ as given.
In this section we investigate the properties of both the filtered and model-implied sequences. The results developed in this section are used in Section~\ref{sec4} to establish the asymptotic properties of the MLE for $\dtheta$.%, and in Section~\ref{sec6} to establish local optimality of score-driven models.

%Also, we can have other dynamic schemes for \eqref{eqgasupdate}, for example, including additional lags of $\dFtildet$ or $\fScaledScore(\dFtildet,\dDatat; \dlambda)$,
%and have the measurement function $\fLink$ and the scaling function $\fScale$ also depend on $\dDataSuptm$ directly.
%However, these generalizations would further burden the (already complex) notation 
%and complicate the formulation of some of the technical conditions without materially affecting the main results.
%We therefore refrain from such generalizations here.

%Given the results in \citet{bougerol1993}
%and \SMM,\myfootnote{%
%    \citet[Theorem 2.8]{smikosch2006} extend 
%    \citet[Theorem 3.1]{bougerol1993} with the uniqueness of 
%    the stationary solution.
%}  %
%we present two related propositions that play their respective roles in
%%each having its own use for
%the applications of Section~\ref{sec5}.
%%Propositions~\ref{prop1} and \ref{prop2} formulate the conditions under which the set of recursions in equations \eqref{eq3.1} and \eqref{eqgasupdate}, respectively, converge to their SE limits and have bounded unconditional moments. 
%%Both propositions are relevant for the setting of a correctly specified model and make use of an independence assumption on the driving variables $\ept$ in \eqref{measurement}. 
%%\showsc{Is it too early to talk about the contraction condition? This is repeated again before and after each theorem.}
%%The main condition in both propositions is that the stochastic recurrence relation is contracting \textit{on average}. 
%%Propositions~\ref{prop3} and \ref{prop4}, on the other hand, are applicable in settings where the model is possibly mis-specified.
%%The contraction conditions in these propositions are stricter than in Propositions \ref{prop1} and \ref{prop2} and need to hold uniformly rather than in expectation. In this sense they are closer, albeit weaker, to the type of conditions formulated in \cite{potscherprucha1997}.
%%We show in Section~\ref{sec5} how the uniformity sometimes poses a challenge to the applicability of the theory in particular examples.

We first introduce some additional notation.
For a scalar random variable $\dX$,
define $\lnormN \dX \rnormN := (\Ee|x|^\normN)^{1/\normN}$ for $\normN > 0$.
If the random variable $\dX(\dtheta)$ depends on a parameter $\dtheta \in \fTheta$,  define 
%the supremum norm 
$\| \dX(\cdot) \rnormNtheta := ( \Ee \sup_{\dtheta \in \fTheta} |\dX(\dtheta)|^{\normN} )^{1/\normN}$.
%Furthermore, we define $\dX^{\iTime_1:\iTime_2}:=\{\dX_{\iTime}\}_{\iTime = \iTime_1}^{\iTime_2}$, and $\dX^{\iTime_2}:=\{\dX_{\iTime}\}_{\iTime = -\infty}^{\iTime_2}$ for any sequence $\{\dX_{\iTime}\}_{\iTime \in \field{Z}}$ and any $\iTime_1,\iTime_2 \in \field{N}$. If the sequence $\{\dX_{\iTime}(\dtheta)\}_{\iTime \in \field{Z}}$ depends on $\dtheta$, we use the short-hand notation $\dX_{\dtheta}^{\iTime_1:\iTime_2} := \dX^{\iTime_1:\iTime_2}(\dtheta)$. 
We say that the sequence $\dXt$ converges exponentially fast almost surely (e.a.s.) to the sequence $\dXt'$ if $c^t\,\|\dXt - \dXt'\| \stackrel{a.s.}{\to} 0$ for some $c>1$; see \cite{smikosch2006}\ for more details.
Finally, we use $\dXt \perp \dXt'$ to denote independence between $\dXt$ and $\dXt'$.
%Finally, $\dX_{\dtheta}$ denotes a nonrandom possible realization for $\dXt(\dtheta)$.


Propositions \ref{prop2} and \ref{prop4} below are written specifically for the score-driven recursion \eqref{eqgasupdate}. 
The propositions can, however, be extended to more general forms which can be found in \SupplementaryAppendix~\ref{AppTechnicalLemmas}. 
First, we consider the score-driven model defined in terms of the error terms $\ept$ rather than in terms of the observations $\dDatat$.
This enables us to establish explicit results for the score-driven model as a potential data generating process and  to derive properties for the MLE under the assumption of a correctly specified model.
Define 
$\fScaledScoreU(\dFut,\ept;\dlambda) := \fScaledScore (\dFut,\fLink(\dFut,\ept);\dlambda)$ and let  
$\{ \dFut \}_{\iTime \in \field{N}}$ be generated by
\begin{equation} \label{NRpg10}
    \dFutp = 
    \domega + 
    \dalpha\, \fScaledScoreU \big(\dFut,\eptl ; \dlambda  \big) + 
    \dbeta\, \dFut ,
\end{equation}
for $\iTime>1$ and initial condition $\dFuone = \dFoneFixed$, where we use $\dFut$ as a shorthand for $\dFut = \dFut(\eplSuptm\supcomma\dtheta,\dFoneFixed)$ if no confusion is caused.
%where  $\eplSuptm:=\{\eptl\}_{ 1\leq t \leq t-1 }$ with each $\eptlambda$ taking values in $\fEp \subseteq \field{R}$. 

\begin{exmc} %\rm
The recursion in \eqref{eq2.4} is defined in terms of $\dDatat$ and $\dFt$. If we define the recursion in terms of $\ept$ and $\dFut$ instead as required by equation \eqref{NRpg10}, we obtain
\bq{exampSu}
    \dFutp = \domega +  
    \left(\dbeta + \dalpha\,\left(
        \frac{(1+\dlambda^{-1}) \ept^2}
        {1+\dlambda^{-1}\ept^2} - 1
    \right)
    \right)\cdot \dFut,
\eq
such that $\fScaledScoreU(\dFut,\ept;\dlambda) = ((1+\dlambda^{-1}) \ept^2/(1+\dlambda^{-1}\ept^2) - 1)\cdot\dFt$.
So whereas the recursion in \eqref{eq2.4} is highly nonlinear in $\dFt$ given $\dDatat$, the recursion in \eqref{exampSu} is linear in $\dFut$ for given $\ept$.
\end{exmc}

We next formulate a result for the stationarity and existence of moments of $\dFut$ as given by \eqref{NRpg10}; compare the specific example in \eqref{exampSu}.
We assume that the scaled score in $\ept$ satisfies $\fScaledScoreU \in \field{C}^{(1,0,0)}(\fF^{*} \times \fEp \times \fLambda)$ for some convex $\fF \subseteq \fFstar \subseteq \field{R}$, i.e., $\fScaledScoreU$ is continuously differentiable in $\dFut$ and continuous in $\ept$ and $\dlambda$.
Define %the %supremum of a $\dK$th-power 
%random derivative function
%\begin{equation*}
%   \fDerutk{\dK}(\dlambda) : = \sup_{\dFstar \in \fFstar} 
%   \big|\fDerut(\dFstar,\dlambda) \big|^{\dK}, \quad \quad  
%   \fDerut(\dFstar,\dlambda) :=  \partial  \fScaledScoreU  (\dFstar, \eptl; \dlambda )/\partial \dF, 
%\end{equation*}
 $\fDerut(\dFstar;\dlambda) :=  \partial  \fScaledScoreU  (\dF, \eptl; \dlambda )/\partial \dF|_{\dF=\dFstar}$ and the supremum
\bq{DefRho}
    \drhotn{\dK}(\dtheta) := \sup_{\dFstar \in \fF} |\dbeta + 
    \dalpha\, \fDerut(\dFstar;\dlambda)|^{\dK}.
\eq
%Finally, let $\fThetaStar$ denote a set of points $\dtheta=(\domega,\dalpha,\dbeta, \dlambda) \in \Omega^{*} \times \mathrm{A}^{*} \times \mathrm{B}^{*} \times \fLambda^{*} \subseteq \field{R}^{4}$.
We then have the following proposition.

\begin{prop} \label{prop2} 
For every $\dtheta \in  \fTheta\subseteq \field{R}^{\dimtheta}$ let  
$\{\eptlambda\}_{\iTime \in \field{Z}}$ be an i.i.d.\ sequence and assume
$\exists \dFlNonRandom \in  \fF$  such that 
\begin{enumerate}
    \item[(i)] $\Ee \NatLogPlus |\fScaledScoreU(\dFlNonRandom,\eponelambda;\dlambda)| <\infty$;
    \item[(ii)] $\Ee \NatLog \drhoonen{1}(\dtheta) < 0$.
\end{enumerate}
Then 
$\{ \dFut(\eplSuptm\supcomma\dtheta,\dFoneFixed) \}_{\iTime \in \field{N}}$ 
converges exponentially fast almost surely (e.a.s.) to the unique stationary and ergodic (SE) sequence 
$\{\dFut(\eplASuptm\supcomma\dtheta)\}_{\iTime \in \field{Z}}$ 
for every $\dtheta \in \fTheta$ as $t \to \infty$.

If furthermore for every $\dtheta \in \fTheta\ \exists \ \ndFfin  > 0$ such that 
\begin{enumerate}
    \item[(iii)] $\| \fScaledScoreU(\dFlNonRandom,\eponelambda;\dlambda) \rnorm_{\ndFfin} < \infty$;
    \item[(iv)] $\Ee \drhotn{\ndFfin}(\dtheta) < 1$;
%   \item[(v)] $\dFt(\eplSuptm\supcomma\dtheta,\dFoneFixed) \perp \fDerutpk{\ndF}(\dlambda) 
%   \ \forall \ (\iTime,\dFoneFixed) \in \field{N} \times \fF$.
    \item[(v)] $\dFut(\eplSuptm\supcomma\dtheta,\dFoneFixed) \perp \drhotn{\ndFfin}(\dtheta)
    \ \forall \ (\iTime,\dFoneFixed) \in \field{N} \times \fF$;
\end{enumerate}
then 
$\sup_{\iTime} \Ee| \dFut(\eplSuptm\supcomma\dtheta,\dFoneFixed) |^{\ndFfin} < \infty$
and  
$\Ee|\dFut(\eplASuptm\supcomma\dtheta)|^{\ndF} < \infty \ \forall \ \dtheta \in \fTheta$ and $\ndF\in[0,\ndFfin)$.
\end{prop}

Proposition \ref{prop2} not only establishes stationarity and ergodicity (SE) of $\dFut$, 
it also establishes existence of unconditional moments.
Furthermore, conditions \textit{(i)} and \textit{(ii)} in Proposition \ref{prop2} also provide an almost sure representation of $\dFut(\eplASuptm\supcomma\dtheta)$ in terms of $\{\eptlambda\}_{\iTime=-\infty}^{\iTime - 1}$. We refer to the \SupplementaryAppendix\ for further details. 


%For simplicity, we have assumed in Proposition \ref{prop2} that $\fF$ does not depend on $\dtheta$. 
%This can easily be relaxed. For example, in Section \ref{secapp} we consider an application where $\fF$ depends on $\domega$ and where the set $\fThetaunf$ in Proposition \ref{prop2} imposes restrictions on the admissible values of $\domega$. In some of the applications, this allows us to replace $\fThetaunf$ by a larger counterpart, which facilitates the verification of the conditions in Proposition~\ref{prop2}. The drawback of these larger counterpart sets, however, is that verification of conditions for consistency and asymptotic normality as formulated in Section~\ref{sec4} sometimes becomes harder.

\begin{rem} \rm
\label{remprop2}
Independence of $\eptl$ and $\dFut(\eplSuptm\supcomma\dtheta,\dFoneFixed)$ is sufficient to imply condition \textit{(v)}, i.e.,
if
$\eptlambda \perp \dFut(\eplSuptm\supcomma\dtheta,\dFoneFixed) \ \forall \ (t,\dtheta,\dFoneFixed)$,
then condition \textit{(v)} in Proposition \ref{prop2} holds.
In addition, Proposition \ref{prop2} also holds if the supremum in \eqref{DefRho} is defined over a larger convex set $\fFstar \supseteq \fF$. The same holds for Proposition \ref{prop4} later on. This can for instance be used if the original space $\fF$ is non-convex.
%Furthermore, conditions \textit{(ii)} and \textit{(iv)} can be substituted by the  (stricter albeit easier to verify) condition
%{\it\begin{enumerate}
%    \item[(iv\,$'$)] $\sum_{k=0}^{\ndF} \binom{\ndF}{\dK} |\dalpha|^{k} \, 
%        |\dbeta|^{\ndF-\dK} \, 
%        \Ee \sup_{\dFstar \in \fFstar} |\fDerut(\dFstar;\dlambda) |^{\dK} < 1$.
%\end{enumerate}}
\end{rem}


\begin{exmc} %\rm
In our main example, the recursion \eqref{NRpg10} is always linear in $\dFut$; see equation \eqref{exampSu}. 
Conditions \textit{(i)} and \textit{(iii)} are trivially satisfied for $0<\dlambda<\infty$, because $(1+\dlambda^{-1})\ept^2/(1+\dlambda^{-1}\ept^2)$ is uniformly bounded in $\ept$ by the constant $\dlambda+1 < \infty$. 
We also have that $\drhoonen{\ndFfin}(\dtheta)$ and $\dFut$ are independent, as the former only depends on $\ept$ and the latter on $\eptm, \eptmm, \ldots$, thus meeting condition \textit{(v)}. 
Conditions \textit{(ii)} and \textit{(iv)} are now satisfied if the factor in front of \eqref{exampSu} has a log-moment or an $\ndF$ moment, respectively. For example, for $\ndFfin=1$ condition \textit{(iv)} collapses to $0<\dbeta<1$.
\end{exmc}

%Independence of $\eptl$ and $\dFt(\eplSuptm\supcomma\dtheta,\dFoneFixed)$ is sufficient to imply condition \textit{(v)}. We summarize this in Remark \ref{remprop2}. 
%The remark also provides a stricter substitute for conditions \textit{(ii)} and \textit{(iv)} based on a straightforward binomial expansion. 
%This stricter condition is often easier to verify for specific models.
%The \SupplementaryAppendix\ contains several additional convenient alternative conditions.

%\medskip


%As a result, we can use Proposition \ref{prop3} later to obtain the asymptotic properties of the MLE in mis-specified models.

Proposition \ref{prop2} will prove convenient in case the model is correctly specified as it describes the properties of the score-driven model as a data generating process as well as the properties of the score filter at the true parameter $\boldsymbol{\theta}_{0} \in \fTheta$.


Irrespective of whether we have correct or incorrect specification of the model, to derive the properties of the ML estimator  we must always analyze the stochastic behavior of the filtered time-varying parameter over different $\boldsymbol{\theta} \in \fTheta$.
Proposition \ref{prop4} stated below is key in establishing the invertibility, moment bounds and e.a.s.\ convergence uniformly over the parameter space $\fTheta$ of the score-driven filtered sequence
$\{\dFt(\dDataSuptm\supcomma \dtheta,\dFoneFixed)\}$, formulated in terms of the data $\{\dDatat\}$ rather than in terms of the innovations $\{\ept\}$ as in equation \eqref{NRpg10}.
To state our subsequent proposition concisely, we define 
$\fDeryt(\dFstar;\dlambda) := \partial \fScaledScore  (\dF, \dDatat; \dlambda)/\partial \dF|_{\dF=\dFstar}$ 
and the supremum 
%\begin{equation*}
%   \fDerytk{\dK}(\dlambda) : = 
%   \sup_{\dFstar \in \fFstar} \big|\fDeryt(\dFstar,\dlambda) \big|^{\dK},
%    \quad \quad  
%   \fDeryt(\dFstar,\dlambda) :=    \partial \fScaledScore  (\dFstar, \dDatat; \dlambda)/\partial \dF,
%\end{equation*}
\begin{align} \label{DefRhoTilde}
    \drhotildetn{\dK}(\dtheta) = \sup_{\dFstar \in \fF}
    | \dbeta + \dalpha\, \fDeryt(\dFstar;\dlambda)|^{\dK}.% \ \text{ with $\fF\subseteq \fFstar\subset \field{R}$. }
\end{align}

%\andresays{$\rightarrow$}
%Throughout we maintain implicitly the regularity condition that, for any given $f \in \mathcal{F}$ and $\lambda \in \Lambda$, the score $s(f,y_{t},\lambda)$ is not invariant (a constant function) in $y_{t}$, and that $\alpha \neq 0$, so that the time varying parameter is stochastic. 
%\andresays{$\leftarrow$ Is this really needed still?? It is somewhat disruptive.}
%This implicit assumption will be made explicit in Assumption \ref{ass6} when it plays a more crucial role.
%In the \SupplementaryAppendix, we show that $\{\dFit{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed)\}$ is generated by the stochastic recurrence equation
%\begin{equation}
%    \label{eqderproc}
%    \dFitp{i} =  \dAit{i}(\dtheta) + \dBt(\dtheta) \dFit{i-1} \quad \ \forall \ (i,\dtheta,\iTime),
%\end{equation}
%where we have suppressed the dependence of $\dFit{i}$, $\dAit{i}(\dtheta)$, and $\dBt(\dtheta)$ on most of their arguments, and where $\dAit{i}(\dtheta)$ and $\dBt(\dtheta)$ are (lengthy) expressions in $\BoldFt^{(0:i-1)}:=(\BoldFt,\ldots,\BoldFt^{(i-1)})$ and in functions that define the core structure of the model,
%such as $\fLinktilde$ and $\ptilde$ which are defined below \eqref{likcomponents} and \eqref{eqscoredriver}, respectively.
%Equation \eqref{eqderproc} allows us to establish the SE properties of $\dFit{i}$ by studying the properties of $\dAit{i}(\dtheta)$ and $\dBt(\dtheta)$. Surprisingly, the latter can be established by imposing primitive conditions directly 
%on the core structure of the model.



\begin{prop} \label{prop4} 
Let $\fTheta \subset \field{R}^{\dimtheta}$ be compact,
$\fScaledScore \in \field{C}^{(1,0,0)}(\fF \times \fData \times \fLambda )$,
and let $\{\dDatat\}_{\iTime \in \field{Z}}$ be an  SE sequence.
Assume $\exists \ \dFlNonRandom \in \fF$ 
such that
\begin{enumerate}
    \item[(i)] $\Ee \NatLogPlus \sup_{\dlambda \in \fLambda} 
    |\fScaledScore(\dFlNonRandom,\dDatat; \dlambda)| < \infty$;
    \item[(ii)] $\Ee \NatLog \sup_{\dtheta \in \fTheta}
        \drhotildeonen{1}(\dtheta)  < 0$.
\end{enumerate}
Then uniformly on $\fTheta$ the sequence 
$\{\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)\}_{\iTime \in \field{N}}$ 
converges e.a.s.~to a unique SE sequence
$\{\dFt(\dDataASuptm\supcomma\dtheta)\}_{\iTime \in \field{Z}}$, 
 as $t \to \infty$.

If furthermore  $\exists \ \ndFfin > 0$ such that 
%\begin{equation*}
%(i) \ \ \|\fScaledScore(\dF,\dDatat; \dlambda)\rSupNorm{\ndF}{\fLambda}<\infty \quad \ , \ \quad  (ii) \ \ \Ee \sup_{\dlambda \in \fLambda} \fDery_{t}^{\ndF}(\dlambda)<\infty
%\end{equation*} 
\begin{enumerate}
    \item[(iii)] $ \|\fScaledScore(\dFlNonRandom,\dDatat; \cdot)\rSupNorm{\ndFfin}{\fLambda}
        < \infty$;
    \item[(iv)] $\Ee \sup_{\dtheta \in \fTheta} \drhotildeonen{\ndFfin}(\dtheta) < 1$;
    \item[(v)] $\sup_{\dtheta\in\fTheta} \dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed) \perp \sup_{\dtheta\in\fTheta} \drhotildetn{\ndFfin}(\dtheta)
        \ \forall \ (\iTime,\dFoneFixed)$;
\end{enumerate} 
then
%$\sup_{\iTime} \| \dFt(\dDataSuptm\supcomma\cdot,\dFoneFixed) \rSupNorm{\ndF}{\fTheta} < \infty$,
%$ \| \dFt(\dDataASuptm\supcomma\cdot) \rSupNorm{\ndF}{\fTheta} < \infty$, and \\ 
$\sup_{\iTime} \|  \dFt(\dDataSuptm\supcomma\cdot,\dFoneFixed) \rSupNorm{\ndFfin}{\fTheta} < \infty$
and  
$\|\dFt(\dDataASuptm\supcomma\cdot)\rSupNorm{\ndF}{\fTheta} < \infty$ for $\ndF \in[0,\ndFfin)$.
\end{prop}

The conditions of Proposition \ref{prop4} are easily satisfied by many specific models. Let us illustrate this point by  turning once again to our main example.

\begin{exmc} %\rm
Consider the volatility model in equation \eqref{eq2.4} with $0 < \underline\dlambda \leq \dlambda \leq \bar\dlambda < \infty$.
From the uniform boundedness of the score in $\dDatat$ for given $\dFlNonRandom$, we obtain that conditions \textit{(i)} and \textit{(iii)} are trivially satisfied. Furthermore,  since
\begin{align} \label{extra1a}
    \fDeryt(\dFstar;\dlambda) &= 
    \frac{
        (1 + \dlambda^{-1}) \dDatat^4/(\dlambda\dFstar{}^2)
    }{
        \left(1 + \dlambda^{-1}\dDatat^2/\dFstar \right)^2
    },
\end{align}
we have that,\footnote{The supremum over $\dFstar$ for fixed $\dlambda$ and $\dDatat$ is reached at either $\dFstar \to \infty $ (yielding the value $\dbeta-\dalpha$) or $\dFstar \to 0$ (yielding the value $\dbeta+\dlambda\dalpha$). Note, however, that the latter is in general unattainable as $\dFt > \min(\dFoneFixed, \domega/(1+\dalpha-\dbeta)) > 0$.} 
\begin{align} \label{extra1b}
%    \drhotildetn{\ }(\dtheta) 
%	& =
	\sup_{\dFstar}
	\left|
		\dbeta - \dalpha 
		+ \dalpha\,
		\frac{(1+\dlambda^{-1})\dDatat^4/(\dlambda\dFstar{}^2)}
		{\big(1+\dDatat^2/(\dlambda\dFstar)\big)^2}
	\right|^{\ }
%	\\ & 
	\leq
	\max\big(
		|\dbeta-\dalpha|\,,\,
		|\dbeta+\dalpha\dlambda|
	\big)^{\ }.
\end{align}
Hence, using Remark \ref{remprop2} and taking the upper bound of the supremum, we can set
    $\drhotildetn{\dK}(\dtheta) =\max(\dbeta-\dalpha\,,\,\dbeta + \dlambda\alpha)^{\dK}$,
given the parameter restriction $\dbeta>\dalpha>0$.
As $\drhotildetn{\dK}(\dtheta)$ is independent of the data $\dDatat$, condition \textit{(v)} is trivially satisfied.
Moreover, conditions \textit{(ii)} and \textit{(iv)} simplify to
\bq{exampcondition}
    \sup_{\dtheta\in\fTheta}
    \max \Big( \dbeta - \dalpha \,,\, \dbeta + \dlambda\alpha \Big) < 1.
\eq

%\begin{figure}[!tbp]
%    \centering
%        \includegraphics[width=0.5\textwidth]{3dfig1.png}
%        \caption{Admissable parameter space for the 
%    $\NatLog$-$F(1,\dlambda)$ location model from %Section~\ref{sec2.1}. A parameter space consisting of all points %below this surface satisfies the requirements of Proposition %\ref{prop4}.}
%    \label{figcc1}
%\end{figure}

\end{exmc}

%We have suppressed the dependence of $\fScaledScore$ on $\dlambda$ in the moment preserving properties by defining $\boldN:=(\ndF,\ndata)$. We can do so without loss of generality, as we have assumed $\dlambda$ to be non-stochastic such that all moments of $\dlambda$ exist.

%The two key conditions in Proposition~\ref{prop4} are the contraction property in condition (iv), the independence in condition (v), and the moment preserving properties of the scaled score $\fScaledScore$ and its derivatives. The latter are used to obtain the  moments of $\dFt$ and its derivatives from those of $\dDatat$, and $\fScaledScore$. These, in turn, results play a crucial role in deriving the moments of the log-likelihood function and its derivatives in Section~\ref{sec4}.

%This proposition establishes existence of SE solutions and of unconditional moments for both
%$\{\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)\}$ and its first two derivatives with respect to $\dtheta$. 
%It will prove crucial both for establishing the asymptotic properties of the MLE in Section~\ref{sec4} and the unconditional optimality result in Section~\ref{sec6}.

%\begin{rem} \rm
%\label{rem1prop4}
%The properties of the sequence $\{\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)\}$
%established in
%Proposition \ref{prop4} hold without the assumptions that $\fScaledScore^{(\boldK)} \in 
%\MomentsSymbol_{\fTheta,\fTheta}(\boldN,\nsk)$, $\ndFd >0$, $\ndFdd >0$,
%or $\ndFd \geq1$ and $\ndFdd \geq1$.  
%\end{rem}  



%\showandre{Redundant notation sentence ``define $\fDeryt=\sup_{\dlambda \in \fLambda^{*}_{*}} \fDeryt(\dlambda)$.''}

In practice, it may be difficult to verify the contraction condition  \textit{(iv)} of Proposition \ref{prop4} when $\drhotildetn{\ }(\dtheta)$ depends on the unknown measure of the data. Furthermore, in such cases,  the independence condition \emph{(v)} is difficult to satisfy since the data sequence is not independent over time. We note however, that the independence only needs to hold for some random variable that bounds $ \drhotildeonen{\ndF}(\dtheta)$ and satisfies the contraction condition. More generally, Remark \ref{rem4} states an alternative uniform condition that is typically available for fat tailed score-driven models and renders both conditions \textit{(iv)} and \textit{(v)}  redundant. 

\begin{rem} \rm
\label{rem4}
If the uniform bound
$\sup_{(\dFstar,\dData,\dtheta) \in \fF \times \fData \times \fTheta} 
    |\dbeta + \dalpha\, \partial \fScaledScore  (\dFstar, \dData; \dlambda  ) / \partial \dF |  < 1
$ holds, as in our main example, then 
we can drop conditions \textit{(iv)} and \textit{(v)} in Proposition~\ref{prop4}. 
%Alternatively, \textit{(iv)} and \textit{(v)} in Proposition~\ref{prop4} can be substituted by  $\sup_{\dtheta \in \fTheta} \sup_{y \in \mathcal{Y}}|\omega + \alpha\fScaledScore(\dFNonRandom^*,y; \dlambda) + \beta \dFNonRandom^*| = |\bar{\phi}(\dFNonRandom^*,\dtheta)| 
%    < \infty$ and  $\sup_{\dtheta \in \fTheta}   \sup_{\dFstar \in \fFstar }  |\partial \bar{\phi}(\dFstar,\dtheta)/\partial f |  <  1$, $\fF \subseteq \fFstar$.
\end{rem}

\noindent Conditions \textit{(iii)} and \textit{(iv)} in Proposition \ref{prop4} imply conditions \textit{(i)} and \textit{(ii)}, respectively. 
We emphasize that under conditions \textit{(i)} and \textit{(ii)} our score filter is \textit{invertible} since we are able to write $\dFt(\dDataASuptm\supcomma\dtheta)$ as a measurable function of all past observations.
Most importantly, the invertibility property ensures that the effect of the initialization $\dFoneFixed$ vanishes as $t \to \infty$, and that  the filter converges to a unique limit process independently of $\dFoneFixed$; see, for example, \cite{Granger197887}, \cite{smikosch2006}, \cite{RePEc:pra:mprapa:46027} and \cite{BGKW2016}.
Establishing invertibility is usually one of the main challenges for nonlinear time series models with time-varying parameters. 

In Section \ref{sec4} we show that the stochastic recurrence approach followed
in Propositions \ref{prop2} and \ref{prop4} allows us to obtain consistency and
asymptotic normality under weaker differentiability conditions than those typically imposed;
see also Section 2.3 of \cite{smikosch2006}.
In particular, instead of relying on the usual pointwise convergence plus
stochastic equicontinuity of \citet{RePEc:cwl:cwldpp:940} and \citet{potscherprucha1994},
we obtain uniform convergence through the application of the ergodic theorem of \citet{rao1962}
for sequences in separable Banach spaces. This constitutes a crucial simplification as working with the third order derivatives of the likelihood of a general score-driven model is typically quite cumbersome. 

%} %




%With these results in place, we can address the asymptotic properties of the MLE.

%When appealing to Remark \ref{remass4}, the consistency and asymptotic normality regions of the parameter space can depend on moments of functions of the data $\dDatat$. In general, it is then often possible to find sub-regions that do not depend on such moments. The examples in Section \ref{secapp}, however, reveal that in certain cases it is more interesting to work with the less restrictive condition in Remark \ref{remass4} and estimate the appropriate moments by their sample counterparts; see also Remark \ref{remprop4}.


%\showsc{The following paragraph was a remark that I don't think has to do with Proposition 4. In Proposition 4, we take both sups and there is nothing to estimate. Isn't this related with using Proposition 2? But then, where are uniform moments on derivative processes? I'm confused... I think that Remark 4 in the next section makes the relevant statement! WITH THE NEW CHANGES THE REMARK IS RELEVANT AGAIN, BUT WE NEED TO DISCUSS ITS INTEGRATION.}
%If the uniform boundedness in equation \eqref{uniformcond} has been established, and $\|\fScaledScore(\dF,\dDatat;\dlambda)\rSupNorm{\ndF}{\fLambda} < \infty$ for some $\ndF\geq 1$, then we can obtain a consistent estimate of a sufficient bound on the SE region if we replace the expectation in $\|\fScaledScore(\dF,\dDatat;\dlambda)\rSupNorm{\ndF}{\fLambda}$ by a sample average. As this moment exists, the average provides a consistent estimate of the expectation. As an example, assume that $\fScaledScore(\dF,\dDatat;\dlambda) = \dDatat^{2}/(1+\dDatat^{2})$. Analytically, this is clearly bounded by 1. If $\dDatat^{2}$ has much mass near 0, however, the upper bound of 1 on $\fScaledScore$ may be too restrictive. An estimate of a much tighter bound, and therefore of a wider SE region, may then be obtained by using the sample average  $\iT^{-1}\sum_{\iTime=1}^{\iT}|\dDatat^{2}/(1+\dDatat^{2})|^{\ndF}$, which is a consistent estimate of the expectation given that this expectation is known to exist (through the analytic bound). The same reasoning holds in cases where $\fScaledScore$ depends on $\dlambda\in\fLambda$.






We end this section by extending the results of Proposition \ref{prop4} to the derivative processes 
$\partial\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)/\partial\dtheta$
and
$\partial^2\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)/\partial\dtheta\partial\dtheta\trans$. We use the stationarity, ergodicity, invertibility and bounded moments for the derivative processes for proving the asymptotic normality of the MLE. 
To simplify the notation, we let $\dFit{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed) \in \mathcal{F}^{(i)}$ denote a vector containing all the $i$th order derivatives of $\dFt$ with respect to $\dtheta$, where $\BoldFOneZeroIFixed \in \mathcal{F}^{(0:i)}$ contains the fixed initial condition for $\dFt$ and its derivatives up to order $i$.
Similarly, $\dFit{0:i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed) \in \mathcal{F}^{(0:i)} = \mathcal{F} \times \ldots \times \mathcal{F}^{(i)}$ denotes a vector containing $\dFt$ as well as its derivatives with respect to $\dtheta$ up to order $i$.
%Our moment bounds use only primitive conditions that are formulated directly in terms
%of the core structure of the model, i.e., in terms of the scaled score $\fScaledScore$ and
%log density $\ptilde$.
%Having bounded moments is a natural requirement in the proofs of the asymptotic properties of the MLE because the likelihood and its derivatives are nonlinear functions of the original data $\dDatat$, of the time varying parameter $\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)$, and of its first two partial derivatives, %with respect to $\dtheta$, i.e.,
%$\partial\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)/\partial\dtheta$
%and
%$\partial^2\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)/\partial\dtheta\partial\dtheta\trans$.
%; see the \SupplementaryAppendix\ for further details. 
Furthermore, in order to work with primitive conditions we use the notion of moment preserving maps, which we define as follows.


\begin{defn}    \label{def1} 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Function $h$, index $i$, and upindex $q$ are only defined here
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \emph{(Moment Preserving Maps)}\\
A function 
$h: \field{R}^{q} \times \fTheta \to \field{R}$  
is said to be $\boldN/\msymbol$-moment preserving, denoted as
$h(\cdot;\dtheta) \in \MomentsSymbol_{\fTheta_1,\fTheta_2} (\boldN,\msymbol)$, 
if and only if 
$\Ee \sup_{\dtheta \in \fTheta_1} |x_{i,t}(\dtheta)|^{\nsymbol_{i}}<\infty$
for
$\boldN = (\nsymbol_{1},\ldots,\nsymbol_{q})$
and
$i=1,\ldots,q$ implies 
$\Ee \sup_{\dtheta \in \fTheta_2} |h(\boldX_{\iTime}(\dtheta);\dtheta)|^{\msymbol}<\infty$.
If $\fTheta_1$ or $\fTheta_2$ consists of a singleton, we replace $\fTheta_1$ or $\fTheta_2$ in the notation by its single element, e.g., 
$\Moments{\boldK}_{\dtheta_1,\fTheta_2}$ 
if $\fTheta_1 = \{\dtheta_1\}$.
\end{defn}


%Note that $h \in \Momentstt{\boldK}(\boldN,m)$ implies $h \in \Momentstt{\boldK}(\boldN,m^{*}) \ \forall \ m^{*} \leq m$. 
Moment preservation is a natural requirement in the proofs of the asymptotic properties of the MLE because the likelihood and its derivatives are nonlinear functions of the original data $\dDatat$, the time varying parameter $\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)$, and derivatives of the score, such as $\partial\fScaledScore(\dFt,\dData;\dlambda)/\partial\dlambda$
or
$\partial^2\fScaledScore(\dFt,\dData;\dlambda)/\partial\dFt\partial\dlambda$.
For example, every polynomial function  $h(x;\dtheta)=\sum_{j=0}^{J} \theta_{j}x^{j} \ \forall \ (x,\dtheta) \in \fX \times \fTheta$, $\dtheta=(\theta_{0},\ldots,\theta_{J}) \in \fTheta \subseteq \field{R}^{J}$ trivially satisfies $h \in \Moments{\dK}_{\dtheta,\dtheta}(n,m)$  with $m=n/J\ \forall \ \dtheta \in \fTheta$. If  $\fTheta$ is compact, then also $h \in \Moments{\dK}_{\fTheta,\fTheta}(n,m)$  with $m=n/J$.
%
%
Similarly, every $k$-times continuously differentiable function $h(\cdot;\dtheta) \in \field{C}^{\dK}(\fX)$ $ \ \forall \ \dtheta \in \fTheta$, with bounded $k$-th derivative $\sup_{x \in \fX}|h^{(k)}(x;\dtheta)| \leq \bar{h}_{\dK}(\dtheta)<\infty \ \forall \ \dtheta \in \fTheta$, satisfies $h \in \Moments{\dK}_{\dtheta,\dtheta}(n,m)$ with $m=n/k \ \forall \ \dtheta \in \fTheta$. If furthermore $\sup_{\dtheta \in \fTheta}\bar{h}_{\dK}(\dtheta) \leq \bar{\bar{h}}_{}<\infty$, then $h \in \Moments{\dK}_{\fTheta,\fTheta}(n,m)$ with $m=n/k$.
The \SupplementaryAppendix\ provides further details and examples of moment preserving maps.
We note that
$ \Moments{\bol dK}_{\fTheta',\fTheta'}(\boldN,\msymbol)  
\subseteq \Moments{\boldK}_{\fTheta,\fTheta}(\boldN,\msymbol^{*})$
for all $\msymbol^{*} \leq \msymbol$, and all $\fTheta \subseteq \fTheta'$.


Using this notation, we let $\fScaledScore \in \Moments{\boldK}_{\fTheta,\fTheta}(\boldN,\ns)$ where $\boldN=(\ndF,\ndata)$, and hence $\ns$ denotes the number of bounded moments of the scaled score $\sup_{\dtheta \in \fTheta}\fScaledScore(\dFt,\dData;\dlambda)$, when $\dFt$ and $\dDatat$ have $\ndF$ and $\ndata$ moments, respectively, uniformly in $\dtheta$. 
Furthermore, as a convention, we let $\nsl$ and $\nsfl$ denote the number of bounded moments for the partial derivatives
$\partial\fScaledScore(\dFt,\dData;\dlambda)/\partial\dlambda$
and
$\partial^2\fScaledScore(\dFt,\dData;\dlambda)/\partial\dFt\partial\dlambda$, 
respectively, when its arguments have $\ndF$ and $\ndata$ moments.
Note that, for the moments of all functions, the argument 
$\dFt$ is always understood to be the stationarity limit filter which has 
$\ndF>0$ moments under appropriate conditions stated in Proposition 
\ref{prop4}. We shall make extensive use of analogous definitions for other 
functions and their partial derivatives.  Finally, we use $\mbare$ to denote moments 
of functions after the taking supremum over $\dFt$. For example, $\msfl$  denotes 
the number of moments of the random variable
$\sup_{\dF}|\partial^2\fScaledScore(\dF,\dData;\dlambda)/ \partial\dF\partial\dlambda|$, uniformly in $\dtheta  \in \Theta$, or in moment preserving notation
\begin{equation*}
\sup_{\dF}\Big|\frac{\partial^2\fScaledScore(\dF,\dData;\cdot)}{\partial\dF\partial\dlambda} \Big| \in  \Moments{\boldK}_{\fTheta,\fTheta}(\boldN,\msfl),
\end{equation*}
with $\boldN=(\ndF,\ndata)$.
We apply the same notational principle to other functions and derivatives.

%, %with respect to $\dtheta$, i.e.,
%$\partial\dFt(\dDataSuptm,\dtheta,\dFoneFixed)/\partial\dtheta$
%and
%$\partial^2\dFt(\dDataSuptm,\dtheta,\dFoneFixed)/\partial\dtheta\partial\dtheta\trans$.
%To simplify the notation, let $\dFit{i}(\dDataSuptm,\dtheta,\BoldFOneZeroIFixed) \in \mathcal{F}^{(i)}$ denote a vector containing all the $i$th order derivatives of $\dFt(\dDataSuptm,\dtheta,\BoldFOneZeroIFixed)$ with respect to $\dtheta$.
%Similarly, $\dFit{0:i}(\dDataSuptm,\dtheta,\BoldFOneZeroIFixed) \in \mathcal{F}^{(0:i)} = \mathcal{F} \times \ldots \times \mathcal{F}^{(i)}$ denotes a vector containing $\dFt$ as well as its derivatives with respect to $\dtheta$ up to order $i$,
%where $\BoldFOneZeroIFixed \in \mathcal{F}^{(0:i)}$ contains the fixed initial condition for $\dFt$ and its derivatives up to order $i$.
%; see the \SupplementaryAppendix\ for further details.



\begin{prop} \label{prop4new} 
Let the conditions of Proposition \ref{prop4} hold with some $\ndFfin>\ndF>0$ and suppose that 
$\fScaledScore \in \field{C}^{(2,0,2)}(\fF \times \fData \times \fLambda )$. 
Let $\mysbar \in \field{C}^{(2,0,2)}(\fF \times \fData \times \fLambda )$ denote the scaled score evaluated at $\dFoneFixed$, i.e., $\fScaledScore(\dFoneFixed,\dDatat;\dlambda)$.

Let $\min\{\ns,\nsl,\msf,\mslf,\msff\}>0$. Then $\{\dFit{1}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroOneFixed)\}_{\iTime \in \field{N}}$ 
converges e.a.s.~to a unique SE sequence
$\{\dFit{1}(\dDataASuptm\supcomma\dtheta)\}_{\iTime \in \field{Z}}$, uniformly in $\fTheta$, and furthermore, we have $\sup_{\iTime} \|  \dFit{1}(\cdot,\BoldFOneZeroOneFixed) \rSupNorm{\ndFdfin }{\fTheta} < \infty$
and  
$\|\dFit{1}(\cdot)\rSupNorm{\ndFd}{\fTheta} < \infty$ for any $\ndFd \in [0,\ndFdfin)$, where 
\begin{align*}
   \ndFdfin & := \min \big\{\ndF\ ,\  \ns \ , \  \nsl \big\}.
\end{align*}

If additionally $\min\{\nsll,\msllf,\mslff,\msfff\}>0$, then the second 
derivative process $\{\dFit{2}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroTwoFixed)\}_{\iTime \in \field{N}}$ 
converges e.a.s.~to a unique SE sequence
$\{\dFit{2}(\dDataASuptm\supcomma\dtheta)\}_{\iTime \in \field{Z}}$, uniformly in $\fTheta$. Furthermore,  $\sup_{\iTime} \|  \dFit{2}(\cdot,\BoldFOneZeroTwoFixed) \rSupNorm{\ndFddfin }{\fTheta} < \infty$
and  
$\|\dFit{2}(\cdot)\rSupNorm{\ndFdd}{\fTheta} < \infty$ for any $\ndFdd \in [0,\ndFddfin)$, where 
\begin{align*}
    \ndFddfin & := \min \Big\{\ndFd\ ,\  \nsll \ , \ \frac{\nsf \ndFd }{\nsf + \ndFd} \ , 
    \ \frac{\nsff \ndFd }{2 \nsff + \ndFd} \ , \ \frac{ \nsfl \ndFd }{ \nsfl + \ndFd} \Big\}.
\end{align*}
\end{prop}




The expressions for $\ndFdfin$ and $\ndFddfin$ may appear complex at first sight.
However, they arise naturally from expressions for the derivative of $\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)$ with respect to $\dtheta$.
Let us turn to our main example and analyze the moment conditions of Proposition \ref{prop4new} in a practical setting. 


\begin{exmc} %\rm
First, by Proposition \ref{prop4}, the limit filtered process $\dFt(\dDataASuptm\supcomma\dtheta)$ is guaranteed to have $\ndF$ moments, uniformly in $\dtheta$, as long as the contraction condition is satisfied. 
Note that $\ndF < \ndFfin$, where $\ndFfin$ is determined via condition \textit{(iii)} of Proposition~\ref{prop4}, which in the case of our main example means we can set $\ndFfin$ arbitrarily high and thus $\ndF>0$, since $\fScaledScoret$ is uniformly bounded in $\dDatat$ for fixed $\dFoneFixed$.
The remaining derivatives are straightforward to check and can be found in the \SupplementaryAppendix. 
From these expressions, we obtain
$\ns,\nsl \leq \ndF$, and $\msf, \mslf,\msff \to \infty$, such that $\min\{\ns,\nsl,\msf,\mslf,\msff\} > 0 $ and $\ndFd < \ndFdfin = \ndF$.
Similarly, we obtain
$\nsll \leq \ndF$ and $\nsf, \nsff, \nsfl, \msllf,\mslff,\msfff \to \infty$, such that $\min\{\nsll,\msllf,\mslff,\msfff\} > 0$ and $\ndFdd < \ndFddfin = \min\{\ndFd, \ndF, \ndFd/2\} = \ndF/2$.
As $\ndF$ can be set arbitrarily high, it is easy to establish moments up to large order for both derivative processes for the score-driven volatility model.
\end{exmc}

We emphasize that the moment conditions stated in Proposition \ref{prop4new} are primitive in the sense that they relate directly to the basic building blocks of the score filter: the score function and its derivatives. 
For the practitioner that wishes to verify moment conditions for any given score model, we provide in \SupplementaryAppendix~\ref{backgroundmomentpreserving} a detailed  compendium of the moment preserving properties of different classes of functions. With this compendium, verifying the primitive moment conditions in Proposition \ref{prop4new} is considerably simplified for many relevant settings of practical interest.



%More generally, it is important to note that we can simplify the moment %requirements substantially by expressing the moments $\ndFd$ and $\ndFdd$ for %the first and second derivative processes in terms of a common minimum moment %bound that holds for all derivatives of $s$. We state this as a separate %remark. Such a common bound may, however, be unnecessarily restrictive.

%\begin{rem} \rm
%\label{remprop4}
%Let the assumptions of  Proposition~\ref{prop4} hold and define
%$\ms := \min\{\ns^{(i,0,j)}: (i,j) \in \field{N}_{0}^{2},\ i+j \leq 2\}$. 
%Then the moment bounds on the derivative processes hold with
%$\ndFd = \ms$ and $\ndFdd = \ms/3$.
%\end{rem}

























% (end)

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------


\section{Global Identification, Consistency and Asymptotic Normality} % (fold) 
\label{sec4}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

%Using all results from Section~\ref{sec3}, w
We now formulate the conditions under which the MLE is strongly consistent and asymptotically normal.
The low-level conditions that we formulate relate directly to the propositions from
Section~\ref{sec3}.
We obtain asymptotic results for the MLE that hold for possibly mis-specified models. These results take the properties of observed data as given. In addition, we also obtain asymptotic properties for the MLE that hold for correctly specified models. The latter results require additional conditions designed to ensure that the score model also behaves well as a data generating process. 
For correctly specified models, we are also able to prove a
new global identification result building on low-level conditions rather than on typical high-level assumptions.

We start with two rather standard assumptions.

\begin{ass}
\label{ass1}
$(\fTheta,\fBorel(\fTheta))$ is a measurable space and $\fTheta$ is  compact.
\end{ass}

\begin{ass}
\label{ass2}
$\fLinktilde\in \field{C}^{(2,0)}(\fF\times\fData)$, 
$\fLinktilde'\in \field{C}^{(2,0)}(\fF\times\fData)$, 
$\ptilde \in \field{C}^{(2,2)}(\fG\times \fLambda)$, and 
$\fScale \in \field{C}^{(2,2)}(\fF \times \fLambda)$,
where $\fG:=\fLinktilde(\fData,\fF)$.
\end{ass}

The conditions in Assumption \ref{ass2} are sufficient for the scaled score to be twice continuously differentiable, i.e.,
$\fScaledScore \in \field{C}^{(2,0,2)}(\fF \times \fData \times \fLambda)$. 
Let $\ProbSpace$ be the event space of the underlying complete probability space.
The next theorem establishes the existence of the MLE.

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\begin{theo} \label{theo1}
\emph{(Existence)} Let Assumptions \ref{ass1} and \ref{ass2} hold.
\ Then there exists a.s.~a measurable map 
$\dthetahatT(\dFoneFixed):\ProbSpace \to \fTheta$ satisfying 
$\dthetahatT(\dFoneFixed) \in \arg\max_{\dtheta \in \fTheta} $ $\LogLikT(\dtheta,\dFoneFixed),$
for all $\iT \in \field{N}$ and every initialization $\dFoneFixed \in \fF$.
\end{theo}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------





%
% i.e., let $\NatLog \fLinktilde' \in \MomentsTT{(2,0)}(\boldN,\nloggtildeprime)$ and $\ptilde \in \MomentsTT{(2,2\diota)}(\boldN,\nptilde)$  as defined below \eqref{likcomponents} and \eqref{eqscoredriver}, respectively, where $\boldN:=(\ndF,\ndata)$.
Using our notation for moment-preserving maps, we let $\NatLog \fLinktilde' \in \MomentsTT{(2,0)}(\boldN,\nloggtildeprime)$ and $\ptilde \in \MomentsTT{(2,2\diota)}(\boldN,\nptilde)$  as defined below \eqref{likcomponents} and \eqref{eqscoredriver}, respectively, where $\boldN:=(\ndF,\ndata)$.
Similarly, we recall that $\fScoret$ denotes the unscaled score $\partial \NatLog \fDensY(\dDatat| \dFt; \dlambda)/\partial \dFt$ and let $\sup_{\dF}|\fScoret| \in \MomentsTT{(2,0)}(\boldN,\mn)$ where $\mn$ denotes the moments of $\sup_{\dF}|\fScoret|$.

To establish consistency, we use the following two assumptions. 

\begin{ass}
\label{ass3}
$\exists \ \fThetaStar \subseteq \field{R}^{\dimtheta} $, $\ndF >0$ and $\ddelta>0$ such that, for every %nonrandom 
$\dFlNonRandom \in \fF$,
\begin{enumerate}
    \item[(i)] $ \| \fScaledScore(\dFlNonRandom,\dDatat; \cdot) \rSupNorm{\ndF+\ddelta}{\fThetaStar}<\infty$;
    \item[(ii)] $\sup_{(\dFstar,\dData,\dtheta) \in \fF \times \fData \times \fThetaStar} 
    |\dbeta + \dalpha \, \partial \fScaledScore(\dFstar,\dData;\dlambda)/\partial\dF|
    <1$.
\end{enumerate}
%or
%\begin{enumerate}
%    \item[(i.b)] $ \| \fScaledScore(\dFlNonRandom,\dDatat; \cdot) \rSupNorm{\ndF}{\fThetaStar}<\infty$;
%    \item[(ii.b)] $\Ee \sup_{\dtheta \in \fThetaStar}
%            \drhotildetn{\ndF}(\dtheta) < 1$;
%    \item[(iii.b)]  $\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed) \perp
%        \drhotildetn{\ndF}(\dtheta) \ \forall \ (t,\dtheta,\dFoneFixed)$.
%\end{enumerate}
\end{ass}

\begin{ass}
\label{ass4}
$\nell = \min \{ \nloggtildeprime, \nptilde\} \geq 1$ and $\mn>0$.
\end{ass}

Assumption \ref{ass3}  ensures the convergence of the  sequence $\{\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)\}$ to an SE limit $\{\dFt(\dDataSuptm\supcomma\dtheta)\}$ with $\ndF$ moments. Alternative primitive conditions leading to the same result can be found in Proposition \ref{prop4} and the subsequent remarks.  Assumption \ref{ass4} ensures one bounded moment for the log likelihood function and a uniform logarithmic moment for its derivative with respect to $\dF$. Both assumptions are stated in terms of the core structure of the score-driven model: the density of the innovations $\ptilde$, the link function $\NatLog\fLinktilde'$, the unscaled score $\fScoret$, and the scaled score $\fScaledScoret$. 
The number of bounded moments of $\ptilde$, $\NatLog\fLinktilde'$,  $\fScoret$ and $\fScaledScoret$ can be easily determined as laid out in \SupplementaryAppendix~\ref{backgroundmomentpreserving}.
We illustrate the verification of these assumptions using our main example.

\begin{exmc} %\rm
From our earlier derivations around equation \eqref{exampcondition}, we already know that the conditions of Assumption~\ref{ass3} can be easily satisfied for an appropriate compact parameter space $\fThetaStar$.
For Assumption \ref{ass4}, note that we have $\fLinktilde'(\dFt,\dDatat) = 0.5\dFt^{-1}$, such that $\nloggtildeprime\to\infty$ given $\dFt \geq \omega > 0$ under the parameter constraint  $\dbeta>\dalpha>0$ and an initialization $\dFoneFixed\geq\domega$. 

Using the expression 
\[
	\ptildet = 
	\NatLog \frac{\Gamma(\frac{\dlambda+1}{2})}{\Gamma(\frac{\dlambda}{2})\sqrt{\dlambda\pi}}
	- \tfrac12(\dlambda+1)
	\NatLog\left(1 + \frac{\dDatat^2}{\dlambda \, \dFt}\right),
\]
it follows immediately that $\nptilde$ can be set arbitrarily large as long as $\ndata>0$. 
The condition $\nell\geq 1$ in Assumption~\ref{ass4} thus only requires the existence of some arbitrarily small moment $\ndata>0$ of the data $\dDatat$.

Finally, since the unscaled score is given by
\begin{equation*}
	\fScore(\dFt,\dDatat;\dlambda)  = 
	\frac{(1+\dlambda^{-1})\dDatat^2}
	{2\dFt^{2}(1+ \dDatat^2/(\dlambda\dFt))} - \frac{1}{2\dFt},
\end{equation*}
it is uniformly bounded in both $\dFt \geq \omega$ and $\dDatat \in \mathbb{R}$, and hence,  $\mn>0$ is trivially satisfied.   

\end{exmc}



Theorem \ref{theo2} establishes the strong consistency of the MLE $\dthetahatT(\dFoneFixed)$.
%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\begin{theo} \label{theo2}
\emph{(Consistency under possible model mis-specification)}
Let $\{\dDatat\}_{\iTime \in \field{Z}}$ be an SE sequence.
Furthermore, let $\Ee|\dDatat|^{\ndata}<\infty$ for some $\ndata\geq 0$ for which also Assumptions \ref{ass1}, \ref{ass2}, \ref{ass3}, and \ref{ass4} hold. 
Finally, let  $\dthetaz \in \fTheta$ be the unique maximizer of the limit log likelihood $\ell_{\infty}(\cdot)$ on the parameter space $\fTheta \subseteq \fThetaStar$ with $\fThetaStar$ as introduced in Assumption \ref{ass3}. Then the MLE satisfies  $\dthetahatT(\dFoneFixed) \stackrel{a.s.}{\to}  \dthetaz$ as $\iT \to \infty$ for every $\dFoneFixed \in \fF$. 
\end{theo}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

We emphasize once more that the proofs and the results of Theorem~\ref{theo2} establish global rather than local consistency. In particular, the assumptions ensure the appropriate limiting behavior of the average log-likelihood over the entire parameter space $\Theta$, rather than in a (possibly arbitrarily small) parameter space around the true parameter value only. This stands in sharp contrast with most of the existing literature on score models, which only delivers local asymptotic results in a neighborhood of $\dtheta_{0}$. 

Theorem~\ref{theo2} also differs from the existing score literature in that it establishes the strong consistency of the MLE in a possibly mis-specified model setting. In particular, consistency of the MLE is obtained with respect to a pseudo-true parameter $\dthetaz \in \fTheta$ that
is \textit{assumed} to be the \textit{unique} maximizer of the limit log-likelihood
$\ell_{\infty}(\dtheta)$. This pseudo-true parameter minimizes the
Kullback-Leibler divergence between the probability measure of $ \ \{\dDatat\}_{t \in \field{Z}} \ $
and the measure implied by the model. 
The result naturally requires regularity conditions on the observed data
$\{\dDatat\}_{\iTime=1}^{\iT} \subset \{\dDatat\}_{\iTime \in \field{Z}}$ that is generated by an unknown data generating process.
Such conditions in this general setting can only be imposed by means of direct assumption. 
However, under an axiom of correct specification, we can restrict the parameter space in such a way that we can \textit{show} that the desired assumptions hold. Specifically, we can show that $\dDatat$ is stationary,  has $\ndata$ moments, and  that $\dthetaz$ is the unique maximizer of the limit log-likelihood function. In this case, the properties of the observed data $\{\dDatat\}_{\iTime=1}^{\iT}$ no longer have to be \textit{assumed}. Instead, they can be \textit{derived} from the properties of the score-driven model under appropriate restrictions on the parameter space. 
By establishing `global identification' we ensure that the limit likelihood has a unique maximum over the entire parameter space rather than only in a small neighborhood of the true parameter. The latter 
is typically used in most of the existing literature and achieved by studying the local properties of the information matrix at the true parameter.

To formulate our global identification result, we introduce a slightly more precise notation concerning the domains and images of the key mappings defining the score-driven model. Define the set  $\fDatag \subseteq \field{R}$ as the image of $\fFg$ and $\fEp$ under $\fLink$, i.e., $\fDatag:=\{\fLink(\dF,\ep), \ (\dF,\ep) \in\fFg \times \fEp\}$, where $\fFg$ denotes the domain (for $\dFt$) of $\fLink$. 
Let $\fEp$ denote the common support of $\fDensEpl \ \forall \ \lambda \in \Lambda$, and let $\fFs$ and $\fDatas$  denote subsets of $\field{R}$ over which the map $\fScaledScore$ is defined.  Below, $\Lambda_{*}$ denotes the orthogonal projection of a set $\fThetaStard \subseteq \field{R}^{\dimtheta}$ onto the subspace $\field{R}^{d_{\lambda}}$ holding the static parameters in $\dlambda$. Furthermore, statements for almost every (f.a.e.) element in a set hold with respect to Lebesgue measure. 
Finally, we let $\fLink \in \MomentsTT{(2,0)}(\boldN,\nfLink)$ with $\boldN=(\ndF,\nsymbol_\ep)$, so that $\nfLink$ denotes the number of bounded moments of $\fLink(\dFt,\ept)$ when $\ept$ has $\nsymbol_\ep$ moments and $\dFt$ has $\ndF$ bounded moments. In practice, the resulting $\nfLink$ bounded moments can be derived from the moment preservation properties laid out in the \SupplementaryAppendix.

The following two assumptions allow us to derive the appropriate properties for 
$\{\dDatat\}_{t\in \field{Z}}$ and 
to ensure global identification of the true parameter. 


%
%
%{\color{red}\textbf{Andre says: there is an issue in part (ii): why sup inside. Is it not outside? and is that not enough, as we require only pointwise moments for the dgp, rather than the uniform ones for estimation; also the $\nfLink$ is not clear and not linked to $\ndata$ and needs to be carefully rewritten to avoid the issues of moment preservation, which is not defined anymore. currently I did not find this $\nfLink$ clear. Also, $> 0$ or $\geq 0$?}}
%
%
\begin{ass}
\label{ass5}
$\exists \ \fThetaStard \subseteq \field{R}^{\dimtheta}$ and $n_\ep\geq 0$ such that 
\begin{enumerate}   
    \item[(i)] $\fEp$ contains an open set for every $\dlambda \in \Lambda_{*}$;
    \item[(ii)]$\sup_{\lambda \in \Lambda_{*}} \field{E} |\ept|^{\nsymbol_\ep}<\infty$ and $\nfLink \geq \ndata>0$.
\item[(iii)]  $\fLink(f,\cdot) \in \field{C}^{1}(\fEp)$ is invertible and $\fLinktilde(f,\cdot) = \fLink^{-1}(f,\cdot) \in \field{C}^{1}(\fDatag)$\ a.e.~$f \in\fFg$;
    \item[(iv)] $p_{y}(y|f;\lambda)=p_{y}(y|f';\lambda')$ holds f.a.e.~$y \in \fDatag$ iff $f=f'$ and $\lambda=\lambda'$. 
\end{enumerate}
\end{ass}

Conditions \textit{(i)} and \textit{(iii)} of Assumption \ref{ass5} ensure that the  innovations $\ept$ have a  non-degenerate support and that  $\fLink(\dF,\cdot)$ is continuously differentiable and invertible with continuously differentiable derivative. As a result, the conditional distribution $p_{y}$ of $\dDatat$ given $\dFt$ is non-degenerate and uniquely defined by the distribution of $\ept$.
Bounded moments for $\dDatat(\dthetaz)$ up to order $\ndata$ follow from moments of $\ept$ and $\dFt$ via condition \textit{(ii)}; see the main example below for an illustration of how to operate this condition. 
Finally, condition \textit{(iv)} states that the static model defined by the observation equation $\dDatat=\fLink(\dF,\ept)$ and the density $p_{u}(\cfdot;\lambda)$ is identified. It requires the conditional density of $\dDatat$ given $\dFt=\dF$ to be unique for every pair $(\dF,\dlambda)$. 
This requirement is very intuitive: one would not extend a static model to a dynamic one if the former is not already identified.

%\showandre{do we need 
%$\deta(\dF; \dlambda) \neq 0 \ \forall \ \dlambda \in %\fLambda$ 
%and $ \dF \in \fF$?
%that seems very strict. or can it just not be a zero function for a given lambda?
%Don't we need
%$\deta(\cdot; \dlambda) \not\equiv 0 \ \forall \ \dlambda \in \fLambda$ ?
%Also, is the sup in the right place (outside the expectation)?}

\begin{exmc} %\rm
For the Student's $t$ volatility model, the domain of $\ept$ is always $\field{R}$, which satisfies part \textit{(i)} of Assumption~\ref{ass5}.
As $\fLink(\dF,\ep)=\dF^{1/2}\ep$, we can use a standard H\"older inequality to obtain $\nfLink=\ndF\cdot\nsymbol_\ep/(2\nsymbol_\ep+\ndF)$, such that parts \textit{(ii)}, \textit{(iii)}, and \textit{(iv)} are satisfied for $\ndF>0$, $0 < \nsymbol_\ep < \inf_{\fLambda_*} \dlambda$, and $\domega>0$, $\dFoneFixed>0$, and $\dbeta>\dalpha>0$.
Note that $\ndF$ follows from Proposition~\ref{prop2}, part \textit{(iii)}, and can be set arbitrarily high.
\end{exmc}



\begin{ass}
\label{ass6}
$\exists\ \fThetaStard \subseteq \field{R}^{\dimtheta}$, $\ndF 
> 0$ and $\ddelta>0$, such that for every $\dtheta \in 
\fThetaStard$ and every
$\dFlNonRandom \in \fFs$ % \subseteq \fFs^*$ 
%either
\begin{enumerate}
    \item[(i)] $\| \fScaledScoreU(\dFlNonRandom,\eponelambda;\dlambda) \rnorm_{\ndF+\ddelta} < \infty$;
%    \item[(ii)] $\Ee \sup_\fTheta \drhotn{\ndF}(\dtheta) < 1$;
    \item[(ii)] $\Ee %\sup_\fTheta 
    \drhotn{\ndF+\ddelta}(\dtheta) < 1$;
\end{enumerate}
%or
%\begin{enumerate}
%        \item[(i.b)] $\sup_{\ep \in \fEp} | %\fScaledScoreU(\dFlNonRandom,\ep;\dlambda) | = %\fScaledScoreU(\dFlNonRandom;\dlambda) < \infty$;
%        \item[(ii.b)] $\sup_{\dFstar \in \fFstar}  |\partial %\fScaledScoreU(\dFstar;\lambda)/\partial f|  <  1$. 
%    \end{enumerate}
Furthermore, $  \alpha \neq 0 \ \forall \ \dtheta \in \fTheta$. Finally, for every $(f,\dtheta) \in \mathcal{F}_{s} \times \fTheta$, 
\begin{equation}
    \label{eq1ass6}
\partial s(f,y,\lambda)/ \partial y \neq 0, %\quad \text{ and } \quad  \frac{\partial^{2} s(f,y,\lambda)}{\partial \lambda \partial y} \neq 0    
\end{equation}
for almost every $\dData \in \fDatag$.
%For every $(f,\lambda,\lambda') \in \mathcal{F}_{s} \times \Lambda \times \Lambda$, 
%\begin{equation}
%   \label{eq2ass6}
%\nexists \gamma \in \field{R} \ \text{ such that } \    \frac{\partial s(f,y,\lambda)}{\partial y} = \gamma \frac{\partial^{2} s(f,y,\lambda')}{\partial \lambda \partial y}   
%\end{equation}
%holds for almost every $y \in \fDatag$. 
\end{ass}

%\chicosays{I commented-out a set of conditions (i.b and ii.b) from the assumption above to make it shorter and simpler. Those conditions are not used in the main example. Feel free to bring them back in!}

Conditions \textit{(i)} and \textit{(ii)} in Assumption \ref{ass6} ensure that the true sequence $\{f_{t}(\dthetaz)\}$ is SE and has $n_{f}$ moments by application of Proposition \ref{prop2} and Remark \ref{remprop2}. Together with condition \textit{(iii)} in Assumption \ref{ass5} we then obtain that the data $\{y_{t}(\dthetaz)\}_{t \in \field{Z}}$ itself is SE and has $\ndata$ moments.
The inequality stated in (\ref{eq1ass6}) in Assumption~\ref{ass6} and the assumption that $\alpha \neq 0$ together ensure that the data $\{y_{t}(\dthetaz)\}$ entering the update equation \eqref{eqgasupdate} render the filtered sequence $\{f_{t}\}$ stochastic and non-degenerate.

Next we show that our leading example satisfies the conditions for our global identification result.  
 \begin{exmc} %\rm
The score $\fScaledScoreU$ is the product of $\dFt$ and a term that is uniformly bounded in $\ept$. Hence,  \textit{(i)} in Assumption~\ref{ass6} is satisfied for arbitrary $\ndF$.
%{\color{red}
Furthermore, by the linearity of $\fScaledScoreU$ in $\dFt$, condition \textit{(ii)} of Assumption \ref{ass6} collapses to 
\[
	\Ee\ \left| \dbeta - \dalpha + \dalpha \frac{(1+\dlambda^{-1})\ept^2}{1+\ept^2/\dlambda} \right|^{\ndF}
%	=
%	\bar\dbeta\cdot\Ee\ \left( \boldsymbol{1}_{\ept^2\leq 1} + \frac{(1+\dlambda^{-1})\ept^2}{1+\ept^2/\dlambda}\cdot \boldsymbol{1}_{\ept^2> 1} \right)^{\ndF}
	< 1.
\]
%where $\bar\dbeta$ is the supremum $\dbeta$ over $\fTheta$, and $\boldsymbol{1}_{E}$ denotes the indicator function for the event $E$.\\
%\textbf{note this is a strange result, as the final inequality depends on $\dlambda$, whereas a sup over $\fTheta$ was taken earlier. I find this very puzzling ...}
%}
In particular, for $\ndF=1$, we obtain the requirement $|\dbeta|<1$, which together with the parameter restrictions to ensure positivity of $\dFt$ result in $1>\dbeta>\dalpha>0$. Larger regions can be obtained for smaller values of $\ndF$.
\end{exmc}

 
%Lemma \ref{lem2} in the Appendix provides a catalog of alternative primitive conditions under which the bound $\bar{\fScaledScore}_{\ep,k}'(\dlambda)$ in Assumption \ref{ass5} can easily be derived.
%Assumption \ref{ass6} states sufficient conditions for the parameters of the score-driven to be identifiable. This leads us to the following theorem.

%We can now state the following result.


\begin{theo}[Global Identification for correctly specified models] \label{theo3}  
    Let Assumptions \ref{ass1}, \ref{ass2}, \ref{ass3}, \ref{ass4}, \ref{ass5}, and \ref{ass6} 
    hold and let the observed data be a subset of the realized path of a stochastic process $\{y_{t}(\dthetaz)\}_{t \in \field{Z}}$ generated by a score-driven model under $\dthetaz \in \fTheta$. 
    Then $Q_{\infty}(\dthetaz)\equiv \field{E}_{\dthetaz} \ell_{t}(\dthetaz) > \field{E}_{\dthetaz} \ell_{t}(\dtheta) \equiv Q_{\infty}(\dtheta) \ \forall \ \dtheta \in \fTheta : \dtheta \neq \dthetaz$.
\end{theo}

The axiom of correct specification thus leads to the global identification result in Theorem \ref{theo3}.
We can use this to establish consistency of the MLE to the true (rather than pseudo-true) parameter value if the model is correctly specified.
This is summarized in the following corollary.

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\begin{cor} \label{cor1}
\emph{(Consistency for correctly specified models)}
    Let Assumptions \ref{ass1}, \ref{ass2}, \ref{ass3}, \ref{ass4}, \ref{ass5}, and \ref{ass6} 
hold and $\{y_{t}\}_{t \in \field{Z}} = \{y_{t}(\dthetaz)\}_{t\in \field{Z}}$ with
$\dthetaz \in \fTheta$, where 
$\fTheta \subseteq \fThetaStar \cap  \fThetaStard$ 
with $\fThetaStar$ and $\fThetaStard$ defined in Assumptions~\ref{ass3}, \ref{ass5} and \ref{ass6}.
%such that $\mathcal{P}_{0} = \mathcal{P}_{\dthetaz}$.
Then the MLE $\dthetahatT(\dFoneFixed)$ satisfies  $\dthetahatT(\dFoneFixed) \stackrel{a.s.}{\to}  \dthetaz$ as $\iT \to \infty$ for every $\dFoneFixed \in \fF$. 
\end{cor}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

The consistency region $\fThetaStar \cap  \fThetaStard$ under correct specification is a subset of the consistency region $\fThetaStar$ for the mis-specified setting. This simply reflects the fact that the axiom of correct specification alone (without parameter space restrictions) is not enough to obtain the desired moment bounds. The parameter space also has to be (further) restricted to ensure that the score-driven data generating process is identified and generates SE data with the appropriate number of moments. 

%\begin{exm}[\sc continued] \rm
%Let $f_{t+1}$ be updated according to
%    \bq{gasgarch}
% \dFtp = \domega+ \dalpha (\dDatat^2 - \dFt) + \dbeta\dFt  
%        = \domega + \dalpha \dDatat^2 + \dbetastar\dFt,
%    \eq
%    with $\dbetastar=\dbeta-\dalpha$,
%    where $\dDatat|\dFt\ \sim\ \Nn(0,\dFt)$, $\domega>0$, and $\dbeta>\dalpha>0$.
%    
%    
%    For a given SE data sequence $\{\dDatat\}$, it is directly clear from \eqref{gasgarch} that we only require  $1>\dbeta-\dalpha>0$ for  $\{\dFt\}$ to be SE.
%    This region coincides with the entire band between the bold solid lines in Figure~\ref{fig0}.
%    
%    Under the axiom of correct specification, however, we can no longer guarantee the SE properties of $\{\dDatat\}$ for all points in the band. 
%    Using the sufficient conditions of, for example, \cite{nelson1990}, we know that $\dDatat$ is SE for all points in the band that lie below the dashed curve $\Ee \NatLog |\dbetastar + \dalpha\, \ept^2|=0$ for standard normally distributed $\ept$. 
%    For the points that lie above this curve, we cannot prove that the corresponding score-driven process is SE. 
%    
%    %If we use a simplified expression of the SE region based on the triangle inequality, the region further reduces to that below the dotted horizontal line, $1 > \dbeta > \dalpha > 0$. There is thus a clear trade-off between the size of the region we obtain, and whether we make assumptions directly on the SE properties and moments of $\dDatat$ itself in a mis-specified model setting, or whether we assume $\dDatat$ to come from a correctly specified score-driven model.
%\end{exm}
%
% 
%
%
%\begin{figure}[!tbp]
%%    \centering
%%        \includegraphics[width=0.5\textwidth]{misspecregion.eps}
%    \centering
%        \,\vspace*{-0.23\textwidth}
%        \includegraphics[width=0.8\textwidth]{misspecregionA.eps}
%
%        \caption{SE, consistency, and asymptotic normality regions
%        under misspecification and correct specification of
%        the score-driven volatility for the normal distribution.}
%    \label{fig0}
%\end{figure}
%

To establish asymptotic normality of the MLE, we impose an assumption that delivers $2+\delta$ moments for the first derivative of the log likelihood function, and $1$ moment for the second derivative. We make use once again of our notation for moment preserving maps. In particular, we let quantities like $\nptilde^{\dlambda}$ and $\nptilde^{\dF \dlambda}$ 
denote the number of bounded moments of the derivative of $\ptilde$ with respect to $\lambda$ and 
the cross derivative with respect to $\dF$ and $\lambda$, respectively. We also let
$\ndFd$ and $\ndFdd$ be defined as in Proposition \ref{prop4new}. Finally, for notational simplicity we define the following quantities, 

\bqn
\nfin & = & 	\min\big\{\nn \ , \ \mnf \ , \ \mnl \ , \ \mnff \ , \ \mnlf \ , \ \mnll \big\} \ ,
\label{eq_nstar}
\\
     \nellp & = & \min \Bigg\{ \nptildel \ , \ \frac{\nn   \ndFd}{\nn +\ndFd}  \Bigg \},
    \label{eq_nellp}
    \\
         \nellpp & = & \min \Bigg\{ 
    \nptilde^{\dlambda \dlambda} \ ,\ 
%    \frac{\nptilde^{\dF\dlambda}\ndFd}{\nptilde^{\dF\dlambda} + \ndFd} \ ,\ 
    \frac{ \nn \ndFdd}{ \nn + \ndFdd} \ , \  
    \frac{ \nnl \ndFd}{ \nnl + \ndFd} \ , \  
    \frac{ \nnf \ndFd}{ 2\nnf + \ndFd}
    \Bigg \} .\\
    \label{eq_nellpp}
    \nonumber
\eqn

%Inspection of the log likelihood and its derivatives in the Technical Appendix reveals that $\nellp$ and $\nellpp$ offer bounds for the moments of the MLE's score and Hessian respectively. 


\begin{ass}
\label{ass7}
$\exists\ \fThetaStarsStar \subseteq \field{R}^{\dimtheta}$ such that 
$\nfin>0$, $\nellpp\geq 1$ and $\nellp > 2+\delta$ for some $\delta>0$.
%$\nsk$, $\nptilde^{(\boldK')}$, and $\nloggtildeprime^{(\boldK'')}$ with
%$\fScaledScore^{(\boldK)} \in \MomentsSymbol_{\fTheta}(\boldN,\nsk)$,


%$\fScaledScore^{(\boldK)} \in \MomentsTTss{}(\boldN,\nsk)$, 
%$\ptilde^{(\boldK')} \in \MomentsTTss{(2,2\diota)}(\ngtilde,\nptilde^{(\boldK')})$,
%$(\NatLog \fLinktilde')^{(\boldK'')} \in \MomentsTTss{(2,0)}(\boldN,\nloggtildeprime^{(\boldK'')})$,
%\begin{eqnarray*}
%\fScaledScore^{(\boldK)} & \in & \MomentsTTss{}(\boldN,\nsk), \qquad \quad
%\ptilde^{(\boldK')} \in \MomentsTTss{(2,2\diota)}(\ngtilde,\nptilde^{(\boldK')}), \\
%%\fLinktilde^{(\boldK')} \in \MomentsTT{(2,0)}(\boldN,\ngtilde^{(\boldK')}), \\
%(\NatLog \fLinktilde')^{(\boldK'')} & \in & \MomentsTTss{(2,0)}(\boldN,\nloggtildeprime^{(\boldK'')}),
%%\qquad
%\end{eqnarray*}
%and $\boldN:=(\ndF,\ndata)$, 
\end{ass}

%\vspace{0.3cm}

Similar to the moment conditions in Proposition~\ref{prop4}, the moment
conditions in Assumption~\ref{ass7} relate directly to low-level (primitive) elements of the model. The expressions in (\ref{eq_nstar}),  (\ref{eq_nellp}) and (\ref{eq_nellpp}) follow directly from the formulas for the derivatives of the 
log-likelihood with respect to $\dtheta$. 
%Consider for example the expression for $\nellp$ in \eqref{eq_nellp}. 
%The first term in the derivative of $\LogLikT(\dtheta,\dFoneFixed)$ with respect to $\dtheta$ 
%is the derivative of the log-density ($\ptildet$) with respect to the static parameter $\dlambda$. Its moments are ensured by $\nptilde^{\dlambda}$. 
%The second term is the derivative of the log Jacobian ($\NatLog \fLinktilde'$) with respect to $\dFt$, multiplied (via the chain rule) by the derivative of $\dFt$ with respect to $\dtheta$. 
%Bounded moments are ensured 
%by the second term in \eqref{eq_nellp} involving $\nloggtildeprime^{\dData}$ and $\ndFd$ through the application of a standard H\"older inequality. 
%The same reasoning applies to the third component of $\nellp$, which corresponds to the derivative of $\ptildet$ with respect to $\dFt$, multiplied by the derivative of $\dFt$ with respect to $\dtheta$.
Having $\nellp > 2+\delta$ facilitates the application of a central limit theorem to the score. Similarly, $\nellpp\geq 1$ allows us to use a uniform law of large numbers for the Hessian. Finally, the condition $\nfin>0$ is designed to ensure that the e.a.s.\ convergence of the filter $\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)$ to its stationary limit is appropriately reflected in the convergence of both the score and the Hessian.

In any case, if one favors simplicity at the cost of some generality, then  the expressions for $\nellp$ and $\nellpp$ can be easily simplified to a single moment condition as stated in the following remark.

\begin{rem} \rm
\label{rem5}
Let $\msymbol$ denote the lowest of the primitive derivative moment numbers $\nptilde^{\lambda}$, $\nn$,  etc. Then $\msymbol \geq 4+\ddelta'$ implies $\nellp> 2+\ddelta$ and $\nellpp \geq 1$, for some positive $\ddelta'$ and $\ddelta$.
\end{rem}

\noindent It is often just as easy, however, to check the moment conditions formulated in Assumption~\ref{ass7} 
directly rather than the simplified conditions in Remark \ref{rem5}. We illustrate this using our main example.

\begin{exmc} %\rm
For the Student's $t$ volatility model, an number of derivative functions need to be computed. These can be found in the \SupplementaryAppendix. Many of these are uniformly bounded functions. In particular, we have 
$\nptildell, \mn, \mnf, \mnl, \mnll, \mnlf, \mnff \to \infty$.
Furthermore, $\nptildel \leq \ndata/\ddelta$ for some (small) $\ddelta>0$. 
Therefore, if some finite moment of $\dDatat$ exists, we can set $\nptildel$ arbitrarily large.
As a result, $\nfin > 0$, $\nellp \leq \min\{\ndata/\ddelta', \ndFd\}$ for arbitary $\ddelta'>0$, and $\nellpp \leq \min\{\ndFdd, \ndFd, \tfrac12\ndFd\}$. We have derived earlier that $\ndFdd < \ndFd/2$, such that $\nellp>2+\ddelta$ and $\nellpp \geq 1$ both imply $\ndFd > 2+\ddelta$. If the contraction condition is met over the entire parameter space, then as also shown earlier we can set $\ndFd$ arbitrarily high and thus statisfy Assumption~\ref{ass7}.
\end{exmc}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------


In well-specified models, the asymptotic normality of the MLE is obtained by applying a central limit theorem (CLT) for SE martingale difference sequences to the ML score. However, as noted in \citet{RePEc:cup:cbooks:9780521252805}, in the presence of dynamic mis-specification, the ML score generally fails to be a martingale difference sequence even at the pseudo-true parameter. As a result, stricter conditions are required to obtain a central limit theorem that allows for some temporal dependence in the ML score. 

Below we use the property of near epoch dependence (NED) to obtain a CLT for the ML score. In particular, we use the uniform filter contraction in Assumption \ref{ass3}.\textit{(i--ii.a)} to ensure that the filter is NED whenever the data is NED. Furthermore, in Assumption \ref{ass8} below, we impose sufficient conditions for the ML score to be Lipschitz continuous on the data as well as on the filter and its derivative. This assumption is designed to guarantee that the ML score inherits the NED property from the data and the filter. The conditions of Assumption \ref{ass8}  can be weakened in many ways; see, for example, \citet{davidson1994} and \citet{potscherprucha1997} for a discussion of alternative conditions. Here the Lipschitz continuity condition allows us to keep the asymptotic normality results clear and simple.

\begin{ass}
\label{ass8}
$\partial \ptildet / \partial \dF$  
and $\partial \NatLog \fLinktildet' / \partial \dF$ 
are uniformly bounded random variables 
and $\partial \ptildet / \partial \dlambda$ is a.s.~Lipschitz continuous 
in $(\dDatat,\dFt)$. 
\end{ass}

\begin{exmc} %\rm
Using the Student's $t$ volatility model, we have already seen that $\dFt\geq\domega>0$ for all $\iTime$. 
The relevant derivative of $\ptildet$ equals $\dFt^{-1}$ times a uniformly bounded function of $\dDatat^2/\dFt$, which obviously results in a uniformly bounded function. Also $\partial \NatLog \fLinktildet' / \partial \dF = 0.5\dFt^{-1}$ is trivially uniformly bounded.
%Uniform boundedness also holds for the scale model with a strictly positive lower bound on the scale parameter.
Furthermore, $\ptildet$ is clearly Lipschitz continuous in $(\dDatat,\dFt)$. Hence Assumption \ref{ass8} holds for the leading example and asymptotic normality applies.
\end{exmc}


The following theorem states the main result for asymptotic normality of the MLE under mis-specification, with $\mathrm{int}(\fTheta)$ denoting the interior of $\fTheta$. 

\begin{theo} \label{theo4}
\emph{(Asymptotic normality under possible model mis-specification)}
Let $\{\dDatat\}_{\iTime \in \field{Z}}$ be SE and  NED of size $-1$ on a strongly mixing process of size $-\delta/(1-\delta)$ for some $\delta>2$. Furthermore, let $\Ee|\dDatat|^{\ndata}<\infty$ for some $\ndata\geq 0$ for which also 
Assumptions \ref{ass1}, \ref{ass2}, \ref{ass3}(i--ii.a), \ref{ass4}, \ref{ass7} and \ref{ass8} are satisfied. Finally, let $\dthetaz \in \mathrm{int}(\fTheta)$ be
the unique maximizer of $\ell_{\infty}(\dtheta)$ on $\fTheta$,
where $\fTheta \subseteq \fThetaStar \cap\fThetaStarsStar $  with $\fThetaStar$ and $\fThetaStarsStar$ as defined in Assumptions \ref{ass3} and \ref{ass7}. Then, for every $\bar{f} \in \mathcal{F}$,  the ML estimator $\dthetahatT(\dFoneFixed)$ satisfies 
\begin{equation*}
    \sqrt{\iT}(\dthetahatT(\dFoneFixed) - \dthetaz) \stackrel{d}{\to} 
    \Nn \big(0,\Infomat^{-1}(\dthetaz)\OPGmat(\dthetaz)\Infomat^{-1}(\dthetaz)\big) 
\ \text{ as } \ \iT \to \infty,
\end{equation*}
where $\Infomat(\dthetaz):=-\Ee\tLogLikt''(\dthetaz)$ is the Fisher information matrix,
$\tLogLikt(\dthetaz)$ denotes the log-likelihood contribution of the $t$-th observation evaluated at $\dthetaz$,
%$\tLogLikt''(\dthetaz)$ is the Hessian of the log-likelihood given in equation \eqref{appinformation} in the Appendix, 
and $\OPGmat(\dthetaz) := \lim_{T \to \infty} T^{-1} \Ee \Big( \sum_{\iTime=1}^{\iT}\tLogLikt'(\dthetaz) \Big) \Big( \sum_{\iTime=1}^{\iT} \tLogLikt'(\dthetaz)\trans \Big)$.
\end{theo}

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\noindent When the model is correctly specified, the ML score can be shown to be  a martingale difference sequence at the true parameter value. As a result,  we no longer need the assumption that the data is NED. Similarly, we can also drop Assumption \ref{ass8}, which was used to ensure that the ML score was also NED. Finally, we no longer need to restrict ourselves to the uniform contraction condition in Assumption \ref{ass3}.\textit{(i--ii.a)}, which guaranteed the NED property for the score filter. 
In general, we are thus presented with a trade-off between the assumption of correct specification combined with weaker additional assumptions, versus the stricter NED conditions without the assumption of correct specification. Apart from this trade-off, the proof of asymptotic normality is the same in both cases.  The following theorem states the asymptotic normality result for the MLE in the context of a correctly specified model.

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\begin{theo} \label{cor2}
\emph{(Asymptotic normality under correct specification)}
    Let Assumptions \ref{ass1}, \ref{ass2}, \ref{ass3}, \ref{ass4}, \ref{ass5}, \ref{ass6}, and \ref{ass7} 
hold and assume $\{y_{t}(\dthetaz)\}_{t\in \field{Z}}$ is a random sequence generated by a score-driven model under some
$\dthetaz \in \mathrm{int}(\fTheta)$ where 
$\fTheta \subseteq \fThetaStar \cap  \fThetaStard \cap  \fThetaStarsStar$ 
with $\fThetaStar$, $\fThetaStard$ and $\fThetaStarsStar$ defined in Assumptions~\ref{ass3}, \ref{ass5}, \ref{ass6}, and \ref{ass7}.
Then, for every $\dFoneFixed \in \mathcal{F}$, the MLE $\dthetahatT(\dFoneFixed)$ satisfies  
\begin{equation*}
\sqrt{\iT}(\dthetahatT(\dFoneFixed) - \dthetaz) 
    \stackrel{d}{\to} 
    \Nn \big(0,\Infomat^{-1}(\dthetaz)\big) \ \text{ as } \ \iT \to \infty,
\end{equation*}
with $\Infomat(\dthetaz)$ the Fisher information matrix defined in Theorem~\ref{theo4}. 
\end{theo}

%The implications of Remark~\ref{rem5} are illustrated in our first example in Section~\ref{sec5}.

%\chicosays{Strictly speaking, I still don't see how this can be a corollary of Theorem 4.4. It would be a corollary if we had conditions ensuring the NED property and Lipschitz continuity under correct specification...  but this is not the case! This result does not follow from the previous theorem... hence it is not a corollary!}

Theorem~\ref{cor2} does not have a separate $\ndata$-moment condition like Theorems~\ref{theo2} and~\ref{theo4}. This stems from the fact that under correct specification the moment conditions for $\dDatat$ are implied by the moment conditions on the data generating process, such as the moment conditions on $\ept$ and $\fLink(\dFt,\dDatat)$ in Assumptions \ref{ass5} and \ref{ass6}.


\begin{exmc} %\rm
To verify the contitions of Theorem \ref{cor2} for the main example, we have already shown that \ref{ass7} requires $\ndF > 2 + \ddelta$. Using the derivations below Proposition~\ref{prop4}, we subsequently showed that this condition is met if the contraction condition \eqref{exampcondition} is satisfied, and if some arbitrarily small moment $\ndata>0$ of $\dDatat$ exist. Given the specification $\fLink(\dFt,\ept) = \dFt^{1/2}\ept$, the latter is ensured if $\inf_\fLambda \dlambda = \underline{\dlambda} > 0$ such that an arbitrarily small moment exists for $\ept$, and (using Proposition~\ref{prop2}) if 
\bq{}
    \sup_\fTheta
    \Ee 
    \left|\dbeta - \dalpha  + \dalpha\,
        \frac{(1+\dlambda^{-1}) \ept^2}
        {1+\dlambda^{-1}\ept^2} 
    \right|^{\ndF} < 1,
\eq
for some small $\ndF$, where $\ept$ has a Student's $t$ distribution with $\dlambda$ degrees of freedom. The condition can easily be checked numerically and ensures that a small moment $\ndF$ exists for $\dFt(\dthetaz)$ for any $\dthetaz$ in the compact parameter space $\fTheta$.
Together, this ensures $\ndata > 0$ under correct specification via a standard H\"older inequality.
The moment conditions on the innovations $\ept$ are thus considerably weaker than in the GARCH case. In particular, the innovations $\ept$ can even have no integer moments, while the asymptotic normality of $\dtheta$ for the score-driven volatility model still applies.
\end{exmc}


The theorems and corollaries derived in this section thus establish the existence, strong consistency, global identification, and asymptotic normality of the MLE for a wide class of score-driven models under correct and incorrect model specification. The scope of the theory developed above can be appreciated even better by considering an additional range of empirically relevant examples, including conditional location models with fat tails, conditional location models with skewness, conditional log-volatility models, conditional duration models with fat-tailed densities, and models for non-linear transformations of location. In all these cases, the current theory can be readily applied.


%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions} \label{sec7}
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%

%In this paper we dealt with an obvious gap in the current literature, namely the lack of 
We have developed
an asymptotic distribution theory for the class of score-driven time-varying parameter models. Despite a wide range of newly developed models using the score-driven approach, a theoretical basis has been missing. We have aimed in this study to make a substantial step forward. 
%
In particular, we have developed a global asymptotic theory for the maximum likelihood estimator
for score-driven models as introduced by \citet{CKL2011,CKL2013} and \citet{harvey2013}. 
%We have shown that the score-driven models possess information theoretic optimality properties under smooth time-variation.
%In particular, when the true conditional densities vary smoothly in time, then, for any given predictive likelihood function, the score-driven filter for the time-varying parameters will provide a better approximation to the true distribution of the data  (in Kullback-Leibler divergence) than any other observation-driven filter.
%This optimality result continues to hold even if the predictive likelihood function is severely mis-specified.
%ur results further complement the earlier literature on score-driven models by formally establishing primitive conditions for the asymptotic properties of the MLE, including global identification, consistency, and asymptotic normality, both in the well-specified and mis-specified settings.
Our theorems are global in nature and are based on primitive, low-level conditions stated in terms of functions that make up the core of the score-driven model.
We also state conditions under which the score-driven model is invertible.
In contrast to the existing literature on score-driven models,  we do not need to rely on the empirically untenable assumption that the starting value $\dFoneFixed$ is both random and observed. 
For the case of correctly specified models, we have been able to establish a global identification result 
that holds under weak conditions.
%Hence our results deviate from the local asymptotics framework that is commonly adopted in the literature.
%Our optimality results substantially extend earlier conditional optimality results for score-driven models.
We believe that the presented results establish a proper foundation for the use of the score function in observation-driven models and for maximum likelihood estimation and hypothesis testing.
%The detailed examples in Section~\ref{sec5} reveal that these conditions lend themselves to verification for empirically relevant models.
%These results show that the MLE can be used effectively for many models in the score-driven class and hence they address an important gap in the current literature.

%To establish the desired asymptotic properties for the MLE estimator we relied on the contraction condition of \cite{bougerol1993}, used also in  \cite{smikosch2006}. We extended their results by also establishing bounds on the unconditional moments of the limiting process.  



%We have shown that the theory does not only establish regions for local, but also for global consistency and asymptotic normality.
%Deriving such regions is typically a challenging problem.
%The same is true in our current context.
%We have highlighted some of the remaining challenges of imposing uniform bounds on derivatives of recurrence relations: for some fat-tailed models these derivatives may become increasingly steep, albeit in an increasingly smaller and arguably less relevant region. 
%Uniform bounds then typically result in very small global consistency and asymptotic normality regions. The regions may be enlarged if one is willing to estimate expectations by sample averages using the observed data.
%We conjecture that further analytic developments in this area should focus on relaxing the 
%uniformity of the contraction condition in order to further enlarge the regions where the MLE can be applied.

% (end)


\appendix 
%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------


\section{Proofs of Main Results} % (fold) 


%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{proof}[Proof of Proposition \ref{prop2}]
This is a special case of Proposition \ref{prop1} in Appendix \ref{AppTechnicalLemmas}.
To see this, set 
$$
    \fStochrec(\dXt(\dVthetaSuptm\supcomma\dtheta,\dXoneFixed),\dVtTheta,\dtheta) = 
    \domega +   \dalpha \fScaledScoreU(\dFt(\eplSuptm\supcomma\dtheta,\dFoneFixed),\ept;\dlambda) + 
    \dbeta\,\dFt(\eplSuptm\supcomma\dtheta,\dFoneFixed),
$$
$\dVtTheta = \ept$, 
and
$\dXt(\dVthetaSuptm\supcomma\dtheta,\dXoneFixed)$ $ = \dFt(\eplSuptm\supcomma\dtheta,\dFoneFixed)$.
Note that $\fScaledScoreU$ is assumed to be 
$\fScaledScoreU \in \field{C}^{(1,0,0)}( \fF \times \fEp \times \fLambda)$ 
for convex $\fF$, such that 
$\fStochrec \in \field{C}^{(1,0,0)}( \fX \times \fV  \times \fTheta)$ with a convex $\fX$.
Conditions \textit{(i)} and \textit{(iii)}--\textit{(v)} in Proposition \ref{prop1} in Appendix \ref{AppTechnicalLemmas}
now directly follow from 
conditions \textit{(i)} and \textit{(iii)}--\textit{(v)} in Proposition \ref{prop2}.
Condition \textit{(ii)} in Proposition \ref{prop1} 
directly follows from 
condition \textit{(ii)} in Proposition \ref{prop2}
by observing that from the mean value theorem we have
\begin{equation*}
    \begin{split}
& \Ee \sup_{(x,x') \in \fX \times \fX : x\neq x'} \frac{| \fStochrec(x,\dVtTheta,
        \dtheta) - \fStochrec(x',\dVtTheta,\dtheta) |^{\dK}}{| x - x' |^{\dK}} \quad \leq\\
&       \Ee \sup_{x^{*}\in \fX} \Big|  \frac{\partial \fStochrec(x^{*},\dVtTheta,\dtheta)}{\partial x}\Big|^{\dK}
        =  \Ee \sup_{\dF^{*}\in \fF} 
        \Big| \dbeta + \dalpha+ \frac{\partial \fScaledScoreU(\dF^{*},\dVtTheta,\dtheta)}{\partial \dF}\Big|^{\dK}
        \ \ \forall\ \dK\geq 1.
    \end{split}
\end{equation*}
\end{proof}

% (end)

%--------------------------------------------------------------
%\begin{trem}
%    \label{rem2prop2}
%Conditions \textit{(iii)}--\textit{(v)} in Proposition 1 of the paper can be substituted by
%\begin{equation*}
%\sup_{\ep \in \fEp} | \fScaledScoreU(\dFlNonRandom^*,\ep;\dlambda) | = | \bar{\fScaledScore}_{u}(\dFlNonRandom^*;\dlambda) | < \infty \quad \text{and}  \quad  \sup_{\dF^{*} \in \mathcal{F} }| \partial \fScaledScoreU(\dF^{*};\dlambda)/\partial \dF |  <  1.
%\end{equation*}
%\end{trem}
%--------------------------------------------------------------



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\proofskip
\begin{proof}[Proof of Proposition \ref{prop4}]
    
The results for the sequence $\{\dFtArgs\}$ are obtained by application of Proposition \ref{prop3} in Appendix \ref{AppTechnicalLemmas} with $\dVt = \dDatat$ and 
$\dXt(\dVSuptm\supcomma\dtheta,\dXoneFixed) =$ 
$\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)$
and
$\fStochrec(\dXt,\dVt,\dtheta) = \domega + \dalpha \fScaledScore(\dFt,\dDatat;\dlambda)
+ \dbeta \dFt$.

\smallskip
\textit{Step 1, SE for $\dFt$:}
Condition \textit{(i)} of Proposition \ref{prop3} holds, because
\EXTRAPROOFSTEP{
    \begin{equation*}
    \begin{split}
        \Ee  \NatLogPlus & \sup_{\dtheta \in \fTheta}
            | \fStochrec(\dXNonRandom,\dVt,\dtheta) -\dXNonRandom |  = \Ee  \NatLogPlus
                \sup_{\dtheta \in \fTheta}
                | \domega + \dalpha \fScaledScore(\dFoneFixed,\dDatat; \dlambda)+ \dbeta 
                \dFoneFixed - \dFoneFixed | \\
            &  \leq  \Ee  \NatLogPlus \sup_{\dtheta \in \fTheta} \Big[  | \domega| +  
            |   \dalpha|\cdot| \fScaledScore(\dFoneFixed,\dDatat; \dlambda)|+ |\dbeta-1|\cdot|\dFoneFixed |  \Big]\\
            &  \leq    \NatLogPlus \sup_{\domega \in \Omega} | \domega| + \NatLogPlus
                \sup_{\dalpha \in \mathcal{A}} |\dalpha| + \Ee \NatLogPlus 
                \sup_{\dlambda \in \fLambda}|   \fScaledScore(\dFoneFixed,\dDatat; \dlambda)
                | \\
            & \quad \quad  + \sup_{\dbeta \in \mathcal{B}} \NatLogPlus |(\dbeta-1)| 
            +   \NatLogPlus |\dFoneFixed|< \infty
    \end{split}
    \end{equation*}
    with $\NatLogPlus \sup_{\domega \in \Omega} |<\infty$, $\NatLogPlus \sup_{\dalpha \in
    \mathcal{A}} |\dalpha|<\infty$ and $\sup_{\dbeta \in \mathcal{B}} \NatLogPlus 
    |(\dbeta-1)|<\infty$ by compactness of $\fTheta$, and $\NatLogPlus |\dFoneFixed|<\infty$ 
    for any $\dFoneFixed \in \mathcal{F} \subseteq \field{R}$,
    and $ \Ee \NatLogPlus 
    \sup_{\dlambda \in \fLambda}| \fScaledScore(\dFoneFixed,\dDatat; \dlambda)|<\infty$ 
    by condition \textit{(i)} in Proposition \ref{prop4}.\\
}
%
Condition \textit{(ii)} in Proposition \ref{prop3} holds, because
\begin{equation*}
    \begin{split}
& \Ee \NatLog \sup_{\dtheta \in \fTheta} \fLip_{1}^{1}(\dtheta)    = \\
%
\EXTRAPROOFSTEP{&\quad  \Ee \NatLog \sup_{\dtheta \in \fTheta} \sup_{(f,f') \in \mathcal{F} \times \mathcal{F} : f \neq f'}\frac{| \domega - \domega  + \dalpha (\fScaledScore(\dF,\dDatat; \dlambda)-\fScaledScore(\dF',\dDatat; \dlambda)) + \dbeta (\dF-\dF')|}{|\dF-\dF'|} \\
}
%
&\quad \leq  \Ee \NatLog \sup_{\dtheta \in \fTheta} \sup_{(f,f') \in \mathcal{F} \times \mathcal{F} : f \neq f'} \frac{ | \dalpha (\fScaledScore(\dF,\dDatat; \dlambda)-\fScaledScore(\dF',\dDatat; \dlambda)) + \dbeta (\dF -\dF')|}{|\dF-\dF'|} \\
\EXTRAPROOFSTEP{&\quad = \Ee \NatLog \sup_{\dtheta \in \fTheta} \sup_{(f,f') \in \mathcal{F} \times \mathcal{F} : f \neq f'} \frac{  |\dalpha \fDeryt(\dFstar;\dlambda) (f - f')+ \dbeta (\dF -\dF')|}{|\dF-\dF'|}\\
}
%
&  \quad   = \Ee \NatLog \sup_{\dtheta \in \fTheta} \sup_{f^* \in \mathcal{F}}  \Big|
    \dalpha \fDeryt(\dFstar;\dlambda) +  \dbeta \Big|   = \Ee \NatLog \sup_{\dtheta \in \fTheta}
        \drhoonen{1}(\dtheta)  < 0,  
    \end{split}
\end{equation*}
where the last inequality follows directly from condition \textit{(ii)} in Proposition~\ref{prop4}.

\smallskip
\textit{Step 2, moment bounds for $\dFt$:}
By a similar argument as in Step 1, we can show that condition \textit{(iv.a)} in Proposition \ref{prop3} follows from condition \textit{(iv)} in Proposition~\ref{prop4}. 
Condition \textit{(iii.b)} in Proposition \ref{prop3} 
for $\normN=\ndFfin$ follows since  by the $C_{r}$-inequality in \cite[p.157]{loeve1977}, 
there exists a $0<c<\infty$ such that
\begin{equation*}
\begin{split}
    \| \fStochrec & (\dXNonRandom,\dVt,\cdot) \rSupNorm{\ndFfin}{\fTheta}    = 
    \Ee  \sup_{\dtheta \in \fTheta}
        | \domega + \dalpha \fScaledScore(\dFNonRandom,\dDatat; \dlambda)+ 
            \dbeta \dFNonRandom |^{\ndFfin} \\
        &  \leq     
        c\cdot \sup_{\dtheta\in \fTheta}  | \domega + \dbeta\dFNonRandom|^{\ndFfin} +   
        c\cdot |\dalpha|^{\ndFfin}\, \Ee
        \sup_{\dtheta\in\fTheta}  
        |\fScaledScore(\dFNonRandom,\dDatat; \dlambda)|^{\ndFfin} < \infty,
\end{split}
\end{equation*}
where the last inequality follows from condition \textit{(iii)} in Proposition~\ref{prop4}, and where $c<1$ for $0<\ndFfin<1$.
Finally, condition \textit{(v.b)} in Proposition \ref{prop3} directly follows from condition \textit{(v)} in Proposition \ref{prop4}.
%The pointwise independence implies the independence of the suprema since, by continuity and compactness, the supremum is obtained at a point $\dtheta \in \fTheta$. 
\end{proof}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\proofskip\noindent 
For the proof of Remark \ref{rem4}, see \SupplementaryAppendix\ \ref{RemainingResults}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\proofskip
%
%
%\andresays{Chico: proof below needs to  be double checked with chico's alterations of the formulation of the proposition.}
%
%
\begin{proof}[Proof of Proposition \ref{prop4new}]
\textit{Step 1, SE for derivatives of $\dFt$:}
The desired result follows by noting that the vector derivative processes 
$\{\dFit{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed)\}_{\iTime\in \field{N}}$ 
for $i=1,2$ and initialized at $\BoldFOneZeroIFixed$ satisfy the conditions of Theorem 2.10 in \cite{smikosch2006} for perturbed stochastic recurrence equations. In particular, they consider a  recurrence of the from $x_{t+1} = \phi_{t}(x_{t})$ where $\{\phi_{t}\}$ converges to an  SE sequence $\{\tilde \phi_{t}\}$ that satisfies the conditions of Bougerol's theorem $\mathbb{E} \log^{+}|\tilde \phi_{t}(0) |<\infty$, $\mathbb{E} \log \sup_{x}|\tilde \phi_{t}'(x)|<\infty$. In particular, one must have a logarithmic moment  $\mathbb{E}\log^{+}|\tilde x_{t}|$ for the solution $\{\tilde x_{t}\}$  of the unperturbed SE system, and the perturbed recurrence must satisfy\footnote{We state the convergence of $\phi_{t}$ at some point $\bar{x}$ rather than at the origin $\phi_{t}(0)$ as in \cite{smikosch2006} since, depending on the application, our recursion may not be well defined at $\bar{x}=0$.} 
\begin{equation*}
	|\phi_{t}(\bar{x}) - \tilde\phi_{t}(\bar{x})| \stackrel{e.a.s.}{\to} 0 \ , \ \ \text{for some $\bar{x} \in \mathbb{R}$} \quad \text{and } \quad \sup_{x}|\phi_t'(x)-\tilde \phi_t'(x)| \stackrel{e.a.s.}{\to} 0 \quad \text{as } \ t \to \infty. 
\end{equation*}
In the present context, the perturbed sequence 
$\{\dFit{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed)\}_{\iTime \in \mathbb{N}}$
depends on the non-stationary sequence
$\{\dFit{0:i-1}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroImFixed)\}_{\iTime \in \mathbb{N}}$, 
which is only stationary in the limit. 
The unperturbed recurrence is equal in all respects, except that it instead depends on the limit SE filter 
$\{\dFit{0:i-1}(\dDataSuptm\supcomma\dtheta)\}_{\iTime \in \mathbb{Z}}$. 

%For convenience, we now omit the initialization vector, and adopt the notation $f_{i,\dtheta,t}:=\dFit{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed)$ and $\BoldF_{0:i,\dtheta,t}:=(f_{0,\dtheta,t},\ldots,f_{i,\dtheta,t})$. Define $\mathbf{v}_{i,t}=(\dDatat,\BoldF_{0:i,\dtheta,t})$.  

In Appendix \ref{secdergen} 
we show that the dynamic equations generating each element of the partial derivative processes take the form
\begin{equation}
    \label{eqderprocproof}
    \dFit{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed)
    \ =\ 
    \dAit{i}(\dtheta,\dFoneFixed) \ +\  
    \dBt(\dtheta,\dFoneFixed)\ \dFitm{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed),
\end{equation}
with 
$\dBt(\dtheta,\dFoneFixed) = \dbeta + \dalpha\,  \partial  \fScaledScore(\dFt(\dtheta,\dFoneFixed),\dDatat; \dlambda) / \partial \dF$ not depending on the order of the derivative $i$. 
The expressions for $\dAit{1}(\dtheta,\dFoneFixed)$ are presented in Appendix \ref{secdergen} and only depend on derivatives up to order $\dFit{i-1}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroImFixed)$. 
Note that both $\dAit{1}$ and $\dBt$ are  written explicitly as a function of $\dFoneFixed$ since they depend on the non-stationary filtered sequence $\dFt(\dtheta,\dFoneFixed)$ initialized at $\dFoneFixed$.
%
%
%{\color{red}\textbf{Andre says: why is the *linearity* so important? I do not see how the differentiated score is linear in $\dFt$ for example in the first derivative's recurrence equation.
%}}
%
%
In contrast, we let $\dAit{1}(\dtheta)$ and $\dBt(\dtheta)$ denote the stationary counterparts of $\dAit{1}(\dtheta,\dFoneFixed)$ and $\dBt(\dtheta,\dFoneFixed)$, respectively,  that depend on the limit stationary filter $\dFt(\dtheta)$. 
The recurrence convergence 	$|\phi_{t}(\bar{x}) - \tilde\phi_{t}(\bar{x})| \stackrel{e.a.s.}{\to} 0$ in \cite{smikosch2006} corresponds  here to  having  $|\dAit{1}(\dtheta,\dFoneFixed) - \dAit{1}(\dtheta)| \stackrel{e.a.s.}{\to} 0$ and $|\dBt(\dtheta,\dFoneFixed)-\dBt(\dtheta)| \stackrel{e.a.s.}{\to}0$. Both conditions are easily verified. Indeed, the expressions in Appendix \ref{secdergen} show that $\dAit{1}(\dtheta,\dFoneFixed)$ satisfies 
\begin{equation*}
|\dAit{1}(\dtheta,\dFoneFixed) - \dAit{1}(\dtheta)| \leq \sup_{f}|\partial \dAit{1}(\dtheta)/\partial \dF | \cdot |\dFt(\dtheta,\dFoneFixed) - \dFt(\dtheta)| 
\end{equation*}
and hence we obtain $|\dAit{1}(\dtheta,\dFoneFixed) - \dAit{1}(\dtheta)| \stackrel{e.a.s.}{\to} 0$ by Lemma 2.1 in \cite{smikosch2006}  since $|\dFt(\dtheta,\dFoneFixed) - \dFt(\dtheta)| \stackrel{e.a.s.}{\to} 0$ by Proposition \ref{prop4} and  $\sup_{\dF}|\partial \dAit{1}(\dtheta)/\partial \dF |$ is SE with a logarithmic moment since 
$\min\{\ns,\nsl,\msf,\mslf\}>0$. Similarly, we obtain 
\begin{equation*}
|\dBt(\dtheta,\dFoneFixed)-\dBt(\dtheta)|\leq 	\sup_{\dF} |\partial \dBt(\dtheta) / \partial \dF | \cdot |\dFt(\dtheta,\dFoneFixed) - \dFt(\dtheta)| \stackrel{e.a.s.}{\to}0 \quad \text{as} \ t\to \infty,
\end{equation*}  
since $\msff>0$ implies that $\sup_{\dF} |\partial \dBt(\dtheta) / \partial \dF |$ is SE with with a logarithmic moment, and  $|\dFt(\dtheta,\dFoneFixed) - \dFt(\dtheta)|$ vanishes e.a.s.
%
The convergence of the Lipschitz coefficients $\sup_{x}|\phi_t'(x)-\tilde \phi_t'(x)| = |\dBt(\dtheta,\dFoneFixed)-\dBt(\dtheta)|\stackrel{e.a.s.}{\to} 0$ follows trivially by the same argument.

For the second derivative process, the same argument using 
Lemma 2.1 in \cite{smikosch2006} applies sequentially. As the argument is slightly more subtle, 
we prove it in Lemma~\ref{lastlemma} of the \SupplementaryAppendix.
%We only need to consider $\dAit{2}(\dtheta)$ since  $\dBt(\dtheta,\dFoneFixed)$ does not depent on $i$.
%Again using the expressions in Appendix \ref{secdergen}, we have $\sup_{\dFit{0:1}}|\partial \dAit{2}(\dtheta) / \partial \dFit{0:1}|$ is SE with a logarithmic moment, by virtue of the fact that $\ndFd>0$ and $\min\{\nsll,\msllf,\mslff,\msfff\}>0$ and $|\dFit{i}(\dDataSuptm\supcomma\dtheta,\BoldFOneZeroIFixed)- \dFit{i}(\dDataSuptm\supcomma\dtheta)| \stackrel{e.a.s.}{\to}0$. 

Finally, we note that the unperturbed recursions  satisfy the conditions of Proposition \ref{prop3}. In the notation of \cite{smikosch2006},  this means not only that the limit recursion $\tilde{\phi}_{t}$ is SE, but also, that its solution $\{\tilde x_{t}\}_{t \in \mathbb{Z}}$ has a logarithmic moment. The logarithmic moment is obtained below.
%By the expression in Appendix \ref{secdergen}  of the technical appendix, we have
%\bq{momentA}
%\Ee  \NatLogPlus \sup_{\dtheta \in \fTheta} | \dAit{i}(\dtheta)|^{\ndF^{(i)}}
%\leq
%\Ee  \sup_{\dtheta \in \fTheta} | \dAit{i}(\dtheta)|^{\ndF^{(i)}} < \infty,
%\eq
%for $i=1,2$.
%Conditions \textit{(i)} and 
%\textit{(ii)} now directly imply conditions \textit{(i)} and \textit{(ii)} in Proposition \ref{prop3}
%for both the first and second derivative processes.
%Since all derivative sequences follow \eqref{eqderprocproof} and 
%$\fScaledScore \in \field{C}^{(2,0,2)}(\fData\times \fF \times \fTheta)$, 
%this implies that  $\{\dAit{i}(\dtheta)\}_{\iTime \in \field{Z}}$ and $\{\dBt(\dtheta)\}_{\iTime \in \field{Z}}$ are continuous functions of $\{\dDatat\}_{\iTime \in \field{Z}}$ and $\{\BoldFt^{(0:i-1)}(\dDataSuptm\supcomma\dtheta)\}_{\iTime \in \field{Z}}$ and hence SE. 
%As a result, since 
%$\Ee\sup_{\dtheta \in \fTheta} |\dBt(\dtheta)|<1$, 
%it follows that 
%$\sup_{\dtheta \in \fTheta} \| \dFit{i}(\dtheta,\BoldFOneZeroIFixed) - \dFit{i}(\dtheta) \| \stackrel{e.a.s.}{\to} 0 $
%as $t \to \infty$, $i=0,1,2$.

\smallskip
\textit{Step 2, moment bounds for derivatives of $\dFt$:}
To establish the existence of moments for the derivative processes,
we need to verify that conditions \textit{(iii.b)}--\textit{(v.b)} of Proposition \ref{prop3} hold. For the limit derivative processes, we can apply Proposition \ref{prop3} directly to the unperturbed system. For the derivative processes initialized at $t=1$, we notice that the moment bounds of Proposition \ref{prop3} can be obtained with non-stationary innovations (see Remark \ref{reminv22}) as long conditions \textit{(iii.b)}--\textit{(v.b)} hold uniformly in $t$. Below, we focus on the process generated by the unperturbed system.


Inspection of the formula for  $\dAit{1}(\dtheta)$ reveals that $\dAit{1}(\dtheta)$  has  $\min \{\ndF\ ,\  \ns \ , \  \nsl \}$ 
bounded moments and $\dAit{2}(\dtheta)$ has  $\ndFddfin$
% = \min \Big\{\ndFd\ ,\  \nsll \ , \ \frac{\nsf \ndFd }{\nsf + \ndFd} \ , \ \frac{\nsff \ndFd }{2 \nsff + \ndFd} \ , \ \frac{ \nsfl \ndFd }{ \nsfl + \ndFd} \Big\}$ 
moments as defined in Proposition~\ref{prop4new}. Inspection of the expression for $\dBt(\dtheta)$ reveals that $\dBt(\dtheta)$ has 
%$\ndFfin>\ndF$ 
$\nsf$
moments. 

Proposition~\ref{prop4new} implies that condition \textit{(iii.b)} in Proposition \ref{prop3} holds with $\ndFdfin$ moments for the first derivative process and $\ndFddfin$ moments for the second derivative process,  since, for any $n>0$, from
the $C_{r}$-inequality in \cite[p.157]{loeve1977}, there exists a $0<c<\infty$ such that,
\begin{equation*}
    \begin{split}
        \Ee \sup_{\dtheta \in \fTheta}
            | \fStochrec(\dXNonRandom,\dVt,\dtheta)|^{n}  = 
            \Ee  \sup_{\dtheta \in \fTheta}
                 | \dAit{i}(\dtheta) + \dBt(\dtheta) \BoldFNonRandomi{i}|^{n} 
            \quad \leq
            \\
                c\cdot \Ee  \sup_{\dtheta \in \fTheta}
                     | \dAit{i}(\dtheta)|^{n} + 
                c\cdot |\BoldFNonRandomi{i}|^{n} 
                \Ee   \sup_{\dtheta \in \fTheta} | \dBt(\dtheta)|^{n} <\infty.
    \end{split}
\end{equation*}
Condition \textit{(iv.b)} in Proposition \ref{prop3} holds with both $n=\ndFdfin$ and $n=\ndFddfin$, since
\begin{equation*}
    \begin{split}
&       \Ee \sup_{\dtheta \in \fTheta} 
            |\dBt(\dtheta)|^{n} \leq
       \Ee \sup_{\dtheta \in \fTheta} 
            \fLip_{1}^{n}(\dtheta) \leq
\EXTRAPROOFSTEP{
    \\  &   \leq  
\Ee   \sup_{\dtheta \in \fTheta} \sup_{(f,f') \in \mathcal{F} \times \mathcal{F} : f \neq f'} \frac{ | \dalpha (\fScaledScore(\dF,\dDatat; \dlambda)-\fScaledScore(\dF',\dDatat; \dlambda)) + \dbeta (\dF -\dF')|^{n}}{|\dF-\dF'|^{n}} \\
& = \Ee   \sup_{\dtheta \in \fTheta} \sup_{(f,f') \in \mathcal{F} \times \mathcal{F} : f \neq f'} \frac{  |\dalpha \fDeryt(\dFstar;\dlambda) (f - f')+ \dbeta (\dF -\dF')|^{n}}{|\dF-\dF'|^{n}}\\
&    = 
}
    \Ee   \sup_{\dtheta \in \fTheta} \sup_{\dFstar \in \fF} 
    \big| \dalpha\fDeryt(\dFstar;\dlambda) + \dbeta\big|^{n}
    < \Ee  \sup_{\dtheta \in \fTheta}
        \drhoonen{^{\ndFfin}}(\dtheta)  < 1,    
    \end{split}
\end{equation*}
because $\ndFfin>\ndF \geq \ndFdfin \geq \ndFddfin$
Finally, %by 
%\showandre{Lemma \ref{SApp.lem5} in the technical appendix,} 
condition $\textit{(v.b)}$ directly implies condition \textit{(v.b)} in Proposition \ref{prop3}. We thus obtain, by Proposition \ref{prop3}, $\ndFdfin$ ($\ndFddfin$) moments  for the first (second) derivative process, initialized at $t=1$, and generated by the unperturbed system, as well as,  $\ndFd$ ($\ndFdd$) moments for the limit process, for any $\ndFd<\ndFdfin$ ($\ndFdd<\ndFddfin$).
\end{proof}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\proofskip
\begin{proof}[Proof of Theorem \ref{theo1}]
The result follows immediately from the differentiability of  $\ptilde$, $\fLinktilde$, $\fLinktilde'$, the compactness of $\fTheta$, and the Weierstrass theorem.
For a detailed proof, see \SupplementaryAppendix\ \ref{RemainingResults}.
\end{proof}

% (end)

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

%\subsection*{Proof of Theorem \ref{theo2}} % (fold) 

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

\proofskip
\begin{proof}[Proof of Theorem \ref{theo2}]
Following the classical consistency argument found 
in for instance \citet[Theorem 3.4]{RePEc:cup:cbooks:9780521252805} or 
\citet[Theorem 3.3]{galwhitbook},
we obtain $\dthetahatT(\dFoneFixed) \stackrel{a.s.}{\to} \dthetaz$ from the uniform convergence of the criterion function
%\begin{equation}
%    \label{eq1pt2}
%\sup_{\dtheta \in \fTheta} |\LogLikT(\dtheta,\dFoneFixed) - \ell_{\infty}(\dtheta)| 
%\stackrel{a.s.}{\to} 0 \ \forall \ \dFoneFixed \in \fF \ \text{ as } \ \iT \to \infty,
%\end{equation} 
and the identifiable uniqueness of the maximizer $\dthetaz \in \fTheta$,
%found e.g.~in \cite{RePEc:cup:cbooks:9780521252805},
\begin{equation*}
    %\label{eq2pt2}
\sup_{\dtheta: \| \dtheta - \dthetaz \| > \ourepsilon} \ell_{\infty}(\dtheta) < \ell_{\infty}
(\dthetaz) \ \forall \ \ourepsilon >0. 
\end{equation*} 

%\smallskip
\textit{Step 1, uniform convergence:}
Let $\LogLikT(\dtheta)$ denote the likelihood $\LogLikT(\dtheta,\dFoneFixed)$ with 
$\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)$
replaced by
$\dFt(\dDataASuptm\supcomma\dtheta)$.
Also define
$ \ell_{\infty}(\dtheta)  = \Ee \tLogLikt(\dtheta) \ \forall \ \dtheta \in \fTheta$,
with $\tLogLikt$ denoting the contribution of the $t$-th observation to the 
likelihood function $\LogLikT$
We have
\bqn
\nonumber
&   \sup_{\dtheta \in \fTheta}|\LogLikT(\dtheta,\dFoneFixed) -  \ell_{\infty}(\dtheta)| \ \leq 
\\ &
\label{ineqsRao}
    \sup_{\dtheta \in \fTheta}|\LogLikT(\dtheta,\dFoneFixed) -  \LogLikT(\dtheta)| +
    \sup_{\dtheta \in \fTheta}|\LogLikT(\dtheta) -  \ell_{\infty}(\dtheta)|.
\eqn
The first term vanishes by application of Lemma 2.1 in \cite{smikosch2006} since  
$\dFt(\dDataSuptm\supcomma\dtheta,\dFoneFixed)$
converges e.a.s.~to 
$\dFt(\dDataASuptm\supcomma\dtheta)$
and $\sup_{\dtheta \in \fTheta} \sup_{\dF}|\nabla \LogLikT(\dtheta)|$ has a logarithmic moment because $\mn>0$. The second term vanishes by
 \citet{rao1962}; see Lemmas \ref{lem4.2.sub1} and \ref{lem4.2.sub2} form \SupplementaryAppendix\ \ref{RemainingResults}, respectively.


%\smallskip
\textit{Step 2, uniqueness:}
Identifiable uniqueness of $\dthetaz \in \fTheta$ follows 
from, for example, \citet{RePEc:cup:cbooks:9780521252805},
by the assumed uniqueness, 
the compactness of $\fTheta$, 
and the continuity of the limit $\Ee\tLogLikt(\dtheta)$ in 
$\dtheta \in \fTheta$, which is implied by the continuity of 
$\LogLikT$ in $\dtheta \in \fTheta \ \forall \ T \in \field{N}$ 
and the uniform convergence of the objective function proved earlier.
\end{proof}

% (end)

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

%\subsection{Proof of Theorem \ref{theo3}} % (fold) 

%\smallskip
\proofskip
\begin{proof}[Proof of Theorem \ref{theo3}]
We index the true $\{f_{\iTime}\}$ and the observed random sequence $\{y_{\iTime}\}$ by the parameter $\dthetaz$, e.g.~$\{y_{\iTime}(\dthetaz)\}$, since  under correct specification the observed data is a subset of the realized path of a stochastic process $\{y_{\iTime}\}_{t \in \field{Z}}$ generated by a score-driven model under $\dthetaz \in \fTheta$.
As conditions \textit{(i)} and \textit{(ii)} of Proposition~\ref{prop2} hold immediately by Assumption \ref{ass6} and condition \textit{(v)} follows immediately from the i.i.d.\ exogenous nature of the sequence $\{u_{\iTime}\}$, it follows by Proposition~\ref{prop2} that the true sequence $\{f_{\iTime}(\dthetaz)\}$ is SE and has at least $\ndF$ moments for any $\dtheta \in \fTheta$. 
The SE nature and $\ndF$ moments of $\{\dFt(\dthetaz)\}$ together with part \textit{(iii)} of 
Assumption~\ref{ass5} imply, in turn, that $\{\dDatat(\dthetaz)\}$ is SE with $\ndata = \nfLink$ moments. 

\smallskip
\textit{Step 1 (formulation and existence of the limit criterion $Q_{\infty}(\dtheta)$):}
As shown in the proof of Theorem~\ref{theo2}, the limit criterion function $Q_{\infty}(\dtheta)$ is well-defined for every $\dtheta\in\fTheta$ by
\begin{equation*}
Q_{\infty}(\dtheta)=\field{E}\tLogLikt(\dtheta)=\field{E}\NatLog p_{\dDatat|\dDatatm,\dDatatmm,\ldots}\Big(\dDatat(\dthetaz)\Big| \dDatatm(\dthetaz), \dDatatmm(\dthetaz), \ldots;\dtheta\Big).
\end{equation*} 
As a normalization, we subtract the constant
$
Q_{\infty}(\dthetaz)% = \field{E}\NatLog p_{y_{\iTime}|y^{t-1}}(y_{\iTime}(\dthetaz)|y^{t-1}(\dthetaz);\dthetaz)    
$
from $Q_{\infty}(\dtheta)$ 
and focus on showing that
\[
Q_{\infty}(\dtheta) - Q_{\infty}(\dthetaz)<0 \ \forall \ (\dthetaz,\dtheta) \in \fTheta \times \fTheta : \dtheta \neq \dthetaz  .
\]
To do this, we use Lemma~\ref{lem4.3.sub1} from \SupplementaryAppendix\ \ref{RemainingResults} and rewrite
\begin{align}
	\notag
            Q_{\infty} (\dtheta) - &Q_{\infty}(\dthetaz) =
	\\
	&
            \int \int \Bigg[ \int \fDensY(y|f,\lambda_{0})  \NatLog\frac{ \fDensY(y|  \tilde{f};\lambda) }{\fDensY(y|f;\lambda_{0} )}  \dd y \Bigg] p_{f_{\iTime},\tilde{f}_{\iTime}}(f,\tilde{f};\dthetaz,\dtheta)
            \dd \dF \dd \tilde{\dF},
	\label{identification1}
\end{align}
for all $(\dthetaz,\dtheta) \in \fTheta \times \fTheta : \dtheta \neq \dthetaz$,
where $p_{f_{\iTime},\tilde{f}_{\iTime}}(f,\tilde{f};\dthetaz,\dtheta)$ is the bivariate pdf for the pair $(\dFt(\dthetaz), \tilde\dFt(\dtheta))$.
We note that the pdf  
$p_{f_{\iTime},\tilde{f}_{\iTime}}(f,\tilde{f};\dthetaz,\dtheta)$
depends on both $\dthetaz$ and $\dtheta$, as for instance the recursion defining $\tilde\dFtildet(\dtheta)$ depends on both $\dtheta$ and on $\dDatat(\dthetaz)$, which in turn depends on $\dthetaz$.
Next, we use Gibb's inequality to show that this quantity is negative for $\dtheta\not=\dthetaz$.



\smallskip
\textit{Step 2 (use of Gibb's inequality):}
Gibb's inequality ensures that, for any given $(f,\tilde{f},\lambda_{0},\lambda) \in \fF \times \tilde{\fF} \times \Lambda \times \Lambda$, the inner integral in \eqref{identification1} satisfies 
    \begin{equation*}
    \int \fDensY(y|f,\lambda_{0}) \NatLog\frac{ \fDensY(y|  \tilde{f};\lambda) }{\fDensY(y|f;\lambda_{0} )}  \dd y  \leq 0    ,
\end{equation*}
with strict equality holding if and only if 
$\fDensY(y|  \tilde{f};\lambda) = \fDensY(y|f;\lambda_{0} )$ 
almost everywhere in 
$\mathcal{Y}$ w.r.t.~$\fDensY(y|f,\lambda_{0})$. 
By Lemma \ref{lem4.3.sub2} from \SupplementaryAppendix\ \ref{RemainingResults} there exists a set
$\fYFF \subseteq \mathcal{Y} \times \fF \times \tilde{\fF}$
with positive probability mass and with orthogonal projections 
$\fYF \subseteq \mathcal{Y} \times \mathcal{F}$,
$\fFF \subseteq \mathcal{F} \times \tilde{\fF}$, 
etc.,
for which (i)--(ii) hold if $\dlambda\not=\dlambda_0$,
and for which (i)--(iii) hold if $\dlambda=\dlambda_0$, 
where
\begin{enumerate}
	\item[(i)] $\fDensY(y|f,\lambda_{0}) >0 \ \forall \ (y,f) \in Y \hspace{-0.1cm} F$; 
	\item[(ii)] if $(\tilde{f},\lambda) \neq (f,\lambda_0)$, then $\fDensY(y|  \tilde{f};\lambda) \neq \fDensY(y|f;\lambda_{0} ) \ \forall \ (y,f,\tilde{f}) \in \fYFF$;
	\item[(iii)] if $\lambda = \lambda_{0}$ and $(\omega,\alpha,\beta) \neq (\omega_{0},\alpha_{0},\beta_{0})$, then $\dF\not=\tilde\dF$ for every $(f,\tilde{f}) \in \fFF$.
\end{enumerate}
Hence, if $\dlambda\not=\dlambda_0$, the strict Gibb's inequality follows directly from (i) and (ii) and the inner integral and the fact that $\fYFF$ has positive probability mass.
If $\dlambda=\dlambda_0$, property (iii) ensures $\dF\not=\tilde\dF$ on a subset $\fFF$ with positive probability mass, and hence the strict inequality again follows via (ii) and (i).
\end{proof} 
 
% (end)




%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------


%\subsection*{Proof of Corollary \ref{cor1}} % (fold) 
\proofskip
\begin{proof}[Proof of Corollary \ref{cor1}]
The desired result is obtained by showing (i) that under the maintained assumptions, $\{\dDatat\}_{\iTime \in \field{Z}} \equiv \{\dDatat(\dthetaz)\}_{\iTime \in \field{Z}}$ is an SE sequence satisfying $\Ee|\dDatat(\dthetaz)|^{\ndata}<\infty$; (ii) that $\dthetaz \in \fTheta$ is the unique maximizer of $\ell_{\infty}(\dtheta,\dFoneFixed)$ on $\fTheta$; and then (iii) appealing to Theorem \ref{theo2}. The fact that $\{\dDatat(\dthetaz)\}_{\iTime \in \field{Z}}$ is an SE sequence is obtained by applying Proposition \ref{prop2} under Assumptions \ref{ass5} and \ref{ass6} to ensure that  $\{\dFt(\dDataSuptm\supcomma\dthetaz,\dFoneFixed)\}_{\iTime \in \field{N}}$ converges e.a.s.~to an SE limit $\{\dFt(\dDataSuptm\supcomma\dthetaz\}_{\iTime \in \field{Z}}$ satisfying $\Ee|\dFt(\dDataSuptm\supcomma\dthetaz)|^{\ndF}<\infty$. This implies by continuity of $g$ on $\fF\times \fEp$ 
\EXTRAPROOFSTEP{(implied by $\fLinktilde\in \field{C}^{(2,0)}(\bar{\fF}\times\fData)$ in
Assumption \ref{ass2})} 
that $\{\dDatat(\dthetaz)\}_{\iTime \in \field{Z}}$ is SE. 
Furthermore, Assumption \ref{ass5} implies that $\Ee|\dDatat(\dthetaz)|^{\ndata}<\infty$ for $\ndata = \nfLink$.
Finally, the uniqueness of $\dthetaz$ is obtained by applying Theorem \ref{theo3} under Assumptions \ref{ass5} and \ref{ass6}.
\end{proof}

% (end) 

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

%\subsection*{Proof of Theorem \ref{theo4}} % (fold) 
\proofskip
\begin{proof}[Proof of Theorem \ref{theo4}]
Following the classical proof of asymptotic normality found e.g.~in
\citet[Theorem 6.2]{RePEc:cup:cbooks:9780521252805}, 
we obtain the desired result from:
\\(i) the strong consistency of $\dthetahatT \stackrel{a.s.}{\to} \dthetaz \in \mathrm{int}(\fTheta)$;
\\(ii) the a.s.~twice continuous differentiability of $\LogLikT(\dtheta,\dFoneFixed)$ in $\dtheta \in \fTheta$;
\\(iii) the asymptotic normality of the score
\begin{equation}
    \label{eqanscoref1}
    \sqrt{\iT}\LogLikT'\big(\dthetaz,\dFzerooneFixed) \stackrel{d}{\to} 
    \Nn(0,\OPGmat(\dthetaz)\big), \qquad
    \OPGmat(\dthetaz) = \Ee\big(\tLogLikt'\big(\dthetaz) \tLogLikt'\big(\dthetaz)\trans \big);
\end{equation}
\\(iv)  the uniform convergence of the likelihood's second derivative,
\begin{equation}
    \label{equcinf}
\sup_{\dtheta \in \fTheta} \big\| \LogLikT''(\dtheta,\dFzerotwoFixed) - \ell_{\infty}''(\dtheta)  \big\| \stackrel{a.s.}{\to} 0;
\end{equation}
\\(v)  the non-singularity of the limit $\ell_{\infty}''(\dtheta) = \Ee\tLogLikt''(\dtheta) = \Infomat(\dtheta)$. 

%\smallskip
\textit{Step 1 (consistency and differentiability)}:
Consistency to an internal point of $\fTheta$ follows immediately by Theorem \ref{theo2} and the additional assumption that $\dthetaz \in \mathrm{int}(\fTheta)$. The differentiability of the likelihood function follows directly by Assumption \ref{ass2} and the expressions for the likelihood in \SupplementaryAppendix\ \ref{likexprs}. 

%\smallskip
\textit{Step 2, CLT:}
The asymptotic normality of the score $\LogLikT'\big(\dthetaz,\dFzerooneFixed)$ in (\ref{eqanscoref1}) follows by  applying a CLT to $\LogLikT'\big(\dthetaz)$,
\begin{equation}
    \label{cltscore2}
    \sqrt{\iT}\LogLikT'\big(\dthetaz) \stackrel{d}{\to} 
    \Nn(0,\OPGmat(\dthetaz)\big),
	\qquad
	\OPGmat(\dthetaz) = 
\lim_{T \to \infty} T^{-1} \Ee \Big( \sum_{\iTime=1}^{\iT}\tLogLikt'(\dthetaz) \Big) \Big( \sum_{\iTime=1}^{\iT} \tLogLikt'(\dthetaz)\trans \Big) < \infty,
\end{equation}
and by showing that the effect of initial conditions vanishes, i.e.,
\begin{equation}
    \label{eqeasscore}
\sqrt{\iT} \| \LogLikT'\big(\dthetaz,\dFzerooneFixed) -  \LogLikT'\big(\dthetaz) \| \stackrel{a.s.}{\to} 0  \ \text{ as } \ \iT \to \infty.
\end{equation}
and by appealing to Theorem 18.10{\small[iv]} in \citet{citeulike:556271}. 
We note that the CLT for SE martingale difference sequences (mds) in \citet{bil1961} cannot be used to obtain (\ref{cltscore2}) as  we allow for model mis-specification, and hence the mds property need not hold. Instead, we obtain (\ref{cltscore2}) by applying the CLT for SE NED sequences in \citet{RePEc:cup:etheor:v:8:y:1992:i:03:p:313-329_01,RePEc:cup:etheor:v:9:y:1993:i:03:p:402-412_00} \citep[see also][]{davidson1994,potscherprucha1997}. Lemma \ref{tlem.NED} in \SupplementaryAppendix\ \ref{AppTechnicalLemmas} ensures that the score $\LogLikT'\big(\dthetaz)$ is a sample average of a sequence that is SE and NED  of size $-1$ on a strongly mixing sequence. In addition, the existence of $\OPGmat(\dthetaz)$ follows from Lemma \ref{lem8} and the assumption that $\nellp\geq 2$ in Assumption \ref{ass7}.
Finally, the a.s.~convergence in \eqref{eqeasscore} follows directly by Lemma \ref{lem4.4.sub2} in \SupplementaryAppendix\ \ref{AppTechnicalLemmas}.



%\smallskip
\textit{Step 3, uniform convergence of $\ell''$:}
The proof of the uniform convergence in (iv) is similar to that of Theorem \ref{theo1}. 
We have
\begin{equation}
    \label{ellppULLN}
    \begin{split}
        \sup_{\dtheta \in \fTheta}\|\LogLikT''(\dtheta,\dFzerotwoFixed) -  
        \ell_{\infty}''(\dtheta)\| & 
    \leq 
        \sup_{\dtheta \in \fTheta}\|\LogLikT''(\dtheta,\dFzerotwoFixed) -  
        \LogLikT''(\dtheta)\| 
%	\\    & \quad \quad \quad \quad \quad 
    + \sup_{\dtheta \in \fTheta}\|\LogLikT''(\dtheta) -  \ell_{\infty}''(\dtheta)\|.
    \end{split}
\end{equation}
The first term on the right-hand side of \eqref{ellppULLN} vanishes a.s.\ by application of Lemma 2.1 in \cite{smikosch2006} since  
$\sup_{\dtheta \in \fTheta}\big\|(\dDatat,\BoldFt^{(0:2)}(\dDataSuptm\supcomma\dtheta,\dFzerotwoFixed)) - (\dDatat,\BoldFt^{(0:2)}(\dDataASuptm\supcomma\dtheta)) \big\| \stackrel{e.a.s.}{\to} 0 $ and  $\sup_{\dtheta \in \fTheta}\sup_{\dF}\|\LogLikT''(\dtheta)|$ has a logarithmic moment; see Lemma \ref{lem4.4.sub4} in \SupplementaryAppendix\ \ref{AppTechnicalLemmas}.

The second term in \eqref{ellppULLN} converges under a bound  
$\Ee \sup_{\dtheta \in \fTheta} \|\tLogLikt''(\dtheta)\|<\infty$
by the SE nature of $\{\LogLikT''\}_{\iTime \in \field{Z}}$. The latter 
is implied by continuity of $\ell''$ on the SE sequence 
$\{(\dDatat,\BoldFt^{(0:2)}(\dDataSuptm\supcomma\cdot))\}_{\iTime \in \field{Z}}$ 
and Proposition 4.3 in \citet{krengel1985}, where SE of
$\{(\dDatat,\BoldFt^{(0:2)}(\dDataSuptm\supcomma\cdot))\}_{\iTime \in \field{Z}}$ 
follows from Proposition \ref{prop4} under the maintained assumptions.
The  moment bound 
$\Ee \sup_{\dtheta \in \fTheta} \|\tLogLikt''(\dtheta)\|<\infty$
follows from $\nellpp\geq 1$ in Assumption \ref{ass7}
and Lemma \ref{lem9} in \SupplementaryAppendix\ \ref{AppTechnicalLemmas}.

Finally, the non-singularity of the limit $\ell_{\infty}''(\dtheta) = \Ee\tLogLikt''(\dtheta) = \Infomat(\dtheta)$ in (v) is implied by the uniqueness of $\dthetaz$ as a maximum of  $\ell_{\infty}''(\dtheta)$ in $\fTheta$ and the usual \emph{second derivative test} calculus theorem.   
\end{proof}









% (end) 

%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

%\subsection*{Proof of Corollary \ref{cor2}} % (fold) 
\proofskip
\begin{proof}[Proof of Theorem \ref{cor2}]
The desired result is obtained by applying Corollary \ref{cor1} to guarantee that under the maintained assumptions $\{\dDatat\}_{\iTime \in \field{Z}} \equiv \{\dDatat(\dthetaz)\}_{\iTime \in \field{Z}}$ is an SE sequence satisfying $\Ee|\dDatat(\boldsymbol{\theta_{0}})|^{\ndata}<\infty$ for $\ndata\geq 0$, and that $\dthetaz \in \fTheta$ is the unique maximizer of $\ell_{\infty}(\dtheta,\dFoneFixed)$ on $\fTheta$. Then the statement follows along the same lines as the proof of Theorem \ref{theo4}.
\end{proof}


%--------------------------------------------------------------
%--------------------------------------------------------------
%--------------------------------------------------------------

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\clearpage

%\bibliographystyle{imsart-nameyear}
\bibliographystyle{chicago}
%\bibliographystyle{apalike}
\bibliography{gasbib}
